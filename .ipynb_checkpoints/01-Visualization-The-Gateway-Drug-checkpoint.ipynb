{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualization Is The Gateway Drug To Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The main point of this is to show you how much you can do with very little. We will get into the hard core (introductory) data science stuff soon, but first lets play. R need not be intimidating you just have to find something fun to do with it and off you will go.\n",
    "\n",
    "I’m actually not sure who said visualization is the gateway drug to statistics but i like it, and its true. If i find out i will add an online errata to the book. But the best way to break down the barriers of R and the scary statistics is to visualize something, so lets get started.\n",
    "\n",
    "I expect that after you see how easy some visuals are in R you will be off and running with your own data explorations. Data visualization is one of the Data Science pillars, so it is critical that you have a working knowledge of as many visualizations as you can, and be able to produce as many as you can. Even more important is the ability to identify a bad visualization, if for no other reason to make certain you do not create one and release it into the wild, there is a site for those people, don’t be those people! Edward Tufte has done some great work in the field of visualizations, one phrase i want to introduce to you is chart junk. Just knowing that phrase exists will make you’re visualizations better, you cer- tainly do not want to have one of your visualizations end up on http://viz.wtf.\n",
    "\n",
    "\n",
    "We are going to start easy, you have installed R Studio, if you have not this would be a great time to do it. Your first visualization is what is typically con- sidered advanced, but I will let you be the judge of that after we are done.\n",
    "\n",
    "**Packages** – Packages are the fundamental units of reproducible Python code. They include reusable Python functions, the documentation that describes how to use them, and sometimes sample data.\n",
    "\n",
    "**Choropleth** – is a thematic map in which areas are shaded or patterned in pro- portion to the measurement of the statistical variable being displayed on the map, such as population density or per-capita income or just about anything you can imagine to stuff into a map.\n",
    "\n",
    "\n",
    "\n",
    "Below is the code for a choropleth, using the package Folium and the data set Civilian_labor_force_2011 which is the population of every county in the US, though very likely out of date.\n",
    "\n",
    "Install package called Folium the quotes are required, you will get a mean-ingless error without them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install folium \n",
    "!pip install json\n",
    "!pip install requests\n",
    "!pip install pydataset\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip will install the package to the notebook instance from the internet  \n",
    "#!pip install folium\n",
    "\n",
    "#import will load the package into memory \n",
    "import folium\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "m = folium.Map(location=[35.5585, -75.4665], zoom_start=6)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/python-visualization/folium/master/examples/data\"\n",
    ")\n",
    "\n",
    "state_geo = f\"{url}/us-states.json\"\n",
    "state_unemployment = f\"{url}/US_Unemployment_Oct2012.csv\"\n",
    "state_data = pd.read_csv(state_unemployment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[48, -102], zoom_start=3)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=state_geo,  #json state polygons\n",
    "    name=\"choropleth\", # Name of map\n",
    "    data=state_data,\n",
    "    columns=[\"State\", \"Unemployment\"],  #columns in teh dataset\n",
    "    key_on=\"feature.id\",  \n",
    "    fill_color=\"YlGn\",  #color \n",
    "    fill_opacity=0.9,  #shading\n",
    "    line_opacity=0.4,  #state border shading\n",
    "    legend_name=\"Unemployment Rate (%)\",  #Legend\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import branca\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/python-visualization/folium/master/examples/data\"\n",
    ")\n",
    "county_data = f\"{url}/us_county_data.csv\"\n",
    "county_geo = f\"{url}/us_counties_20m_topo.json\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(county_data, na_values=[\" \"])\n",
    "\n",
    "colorscale = branca.colormap.linear.YlOrRd_09.scale(0, 50e3)\n",
    "employed_series = df.set_index(\"FIPS_Code\")[\"Civilian_labor_force_2011\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIPS** codes are numbers which uniquely identify geographic areas.  The number of \n",
    "digits in FIPS codes vary depending on the level of geography.  State-level FIPS\n",
    "codes have two digits, county-level FIPS codes have five digits of which the \n",
    "first two are the FIPS code of the state to which the county belongs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employed_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def style_function(feature):\n",
    "    employed = employed_series.get(int(feature[\"id\"][-5:]), None)\n",
    "    #print(employed)\n",
    "    return {\n",
    "        \"fillOpacity\": 1,\n",
    "        \"weight\": .1,\n",
    "        \"fillColor\": \"#black\" if employed is None else colorscale(employed),\n",
    "    }\n",
    "\n",
    "\n",
    "m = folium.Map(location=[48, -102], tiles=\"cartodbpositron\", zoom_start=3)\n",
    "\n",
    "folium.TopoJson(\n",
    "    json.loads(requests.get(county_geo).text),\n",
    "    \"objects.us_counties_20m\",\n",
    "    style_function=style_function,\n",
    ").add_to(m)\n",
    "\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy the code above, create a new dataset using a differnet column and create a new map. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "*****\n",
    "*****\n",
    "\n",
    "# THE HISTOGRAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably have noticed that Python behaves very much like a scripting language which for me, having been a T-SQL guy seemed familiar. You may have noticed that it behaves like a programing language too in that you can install a package, invoke function or data set stored in that package, very much like a dll, though no compiling is required. \n",
    "\n",
    "It’s clear that it is very flexible as a language, which you will learn is its strength and its downfall. If you decide to start designing your own Python packages, you can write them as terribly as you want, though i would rather you didn’t.\n",
    "\n",
    "There are lots of places to find datasets, pydataset, seaborn, Scilit-learn, pandas, NLTK.  This will provide you nice list of datasets to doodle with, as you learn something new explore the datasets to see how you can apply your new-found knowledge.\n",
    "\n",
    "Examples below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "#!pip install pydataset\n",
    "from pydataset import data\n",
    "\n",
    "# Check out datasets\n",
    "data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Check out available datasets\n",
    "print(sns.get_dataset_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "# https://scikit-learn.org/stable/datasets.html\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "X, y = load_boston(return_X_y=True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#https://www.nltk.org/book/ch02.html\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets check out the histogram. If you have worked with SQL you know what a histogram is, and it is marginally similar to a statistics visual histogram. We are going to look at a real one. The basic definition is that it is a graphical representation of the distribution of numerical data.\n",
    "\n",
    "When to use it? When you want to know the distribution of a single column or variable.\n",
    "Typically you will be using the Pandas hist command, we will start with that. \n",
    "\n",
    "First we have to load a dataset into Pandas, we will play with lots of datasets, but i want you to get used to being very good at one data set, the EPA MPG dataset from 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # laod the package for use\n",
    "epa = pd.read_csv(\"https://raw.githubusercontent.com/sqlshep/SQLShepBlog/master/data/epaMpg.csv\")  #read in a file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa  #display the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa['FuelEcon'].hist()  # this method will select the column and perform a basic histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa['FuelEcon'].hist(bins = 30) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa.hist() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn try a couple of histograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the ongoing visualization show and tell scatterplots have come up next on my list. As I write this I try very hard to check and double check my knowledge and methods, I usually have a dataset or two in mind long before I get to the point I want to write about it. I want to use the epa dataset again to play around with and run a line through the scatter plot to show a trend.\n",
    "\n",
    "\n",
    "Below we have loaded the epa dataset,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epa.plot.scatter(x='HorsePower',\n",
    "                y='FuelEcon',figsize=(10,8))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the scatterplot we have two dimensions of data, on the left is the y axis, the FuelEconof the vehicle in ,iles per gallon, and on the bottom is the x axis HorsePower.\n",
    "\n",
    "That was cool, no? Notice Anything interesting about the scatter plot?  Is there an outlier? \n",
    "\n",
    "Something else you can notice is that as the horse power increases the MPG tends to decrease indicating a trend. \n",
    "\n",
    "I wonder if we can write a script to draw a linear regression line through the plot? We will dive deeper into what exactly that line means and what you can do with it later, but know it exists. \n",
    "\n",
    "Yes, we will use Seaborn for this. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot = sns.lmplot(x='HorsePower', y='FuelEcon', data=epa, fit_reg=True,height=8.27, aspect=11.7/8.27)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn, choose a couple of numeric columns in the dataset a perform a scater plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Boxplot or, whisker plot! You will see this one, and its always a little fuzzy to recall what is what until you have been doing it for a while.\n",
    "\n",
    "It is said a picture is worth a thousand words, so will leave these here. THer following two samples are from the epa dataset, so you can easily recreate them. Quartiles is coming up in the next chapter, so if you need to can jump to the Range and IQR section if you need to then come back to this. \n",
    "\n",
    "But for now, just know that The IQR describes the middle 50% of values when ordered from lowest to highest. To find the interquartile range (IQR), first find the median (middle value) of the lower and upper half of the data. These values are quartile 1 (Q1) and quartile 3 (Q3). The IQR is the difference between Q3 and Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epa.boxplot(column=['FuelEcon'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the data points that fall outside the plot?  Those are called Outliers; An outlier is an observation that is numerically distant from the rest of the data. When reviewing a box plot, an outlier is defined as a data point that is located outside the whiskers of the box plot, typically 1.5 * the +/- IQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa.boxplot(column=['Cylinders'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa.boxplot(column=['HorsePower'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try some on your own..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Violin Box plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is more eyecandy, but you can see the distribution of the data. \n",
    "\n",
    "A violin plot plays a similar role as a box and whisker plot. It shows the distribution of quantitative data across several levels of one (or more) categorical variables such that those distributions can be compared. Unlike a box plot, in which all of the plot components correspond to actual datapoints, the violin plot features a kernel density estimation of the underlying distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = sns.violinplot(x=\"Cylinders\", y=\"FuelEcon\", data=epa)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
