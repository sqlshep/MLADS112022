{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Intro to Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we will cover statistics terms and basic visualizations.\n",
    "\n",
    "Let me take this opportunity to apologize. Statistics is necessary, i will try to make it as painless as possible and i am going to give you the absolute essentials. There is no escaping it, you are going to have to know some stats stuff. Through out the notebooks i will cover some of this, its good for me to brain dump to paper every now and then, and its good for you to try and as- similate it. Nothing is going to make sense without it. It only hurts a little bit and \n",
    "\n",
    "I am going to try and give as many samples as possible and break down each concept as much as I possibly can. In the end you will be grate- ful for software, but stats came from long hand math calculations and have formulas that look like they could single handedly put a rocket in space.\n",
    "\n",
    "Stick with it, it gets better, except for probability, probability does not get better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMMON TERMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are a RDBMS gal or guy some of the definitions will seem wonky, and if you are talking to an academic this will be the first communication breakdown, hopefully this will help.\n",
    "\n",
    "\n",
    "Lets get some definitions out of the way, these are critical, it does not mean you need to question the lingo you use on a daily basis, but if you hear it from you statisticians or DS folks, make sure you are on the same page.\n",
    "\n",
    "\n",
    "**Population** – A population is ALL THE DATA. As a data guy I lived in a world where if we were trying to make a decision we used all the data, this is why we had SQL performance problems, our customers sucked at statistics and did not know there was a way to sample a data set. That being said, i also would not like to check my bank account balance based on a sample. So, when you see a population referenced that means the entire data, all of it. If I am using a population of the United States, that means I am using all 330 million or so people in the US for my research. In Sta- tistics, it is denoted as an uppercase N.\n",
    "\n",
    "\n",
    "**Census** – A census is a study of EVERYTHING in a given popula- tion. Most countries have a census. One of the more popular results of the census is the American Community Survey, it frequently provides great sta- tistical training and research material.\n",
    "\n",
    "\n",
    "**Sample** – A sample is as it sounds, it’s a sample of a population, hence not all the data. There are sub-classes of samples we will get into later. But for now know that a sample is a portion of a population. In Sta- tistics, it is denoted as an lowercase n.\n",
    "\n",
    "\n",
    "**Parameter** – A parameter is a numerical quantity that tells us some- thing about the population, such as quantity of a specific ethnicity, number high school graduates, proportion of singles. Do not confuse this with a nu- meric quantity of sample, that is called a statistic. Ah ha!\n",
    "\n",
    "**Variable** – A variable in statistics is what most SQL Folks, me included call a column, there is a very long definition, they contain anything that describe a characterization, qualitative and quantitative.\n",
    "\n",
    "\n",
    "**Case** – A case in statistics is a single row of data. You can imagine that if you have a patient, all of the columns(variables) will make up the data for that patient, hence it is called a case. So, if you hear this outside of academia see if they are discussing a row, or something else entirely. Usual- ly, this terminology references something sciencey, less so outside of med- ical research or scientific fields. I have never heard a row of banking data referred to as a case.\n",
    "\n",
    "**Data** – Plural for of data. Some get bent out of shape over the use of this, I find them more annoying than the usage, I mean its not like I am us- ing there their they’re incorrectly.\n",
    "\n",
    "**Datum** – Singular form of data.\n",
    "\n",
    "**Qualitative Data** – In many respects this is an easy one, if its not Quantitative its probably Qualitative, another more familiar name for it is categorical or, a category. Categorical data is defined as which? Which col- or, which model of, which dog breed, which grade are you in.\n",
    "\n",
    "If you recall, looking at the dataset we used for the Florida education choropleth you will recall that there was a variable called ruralurbancontinuum , though it was a number it was used as a categorical value. The values of this field are 1-9 and related to a category of population density used US wide. In this case no math could be done gainst the value even though it is a num- ber, the Census could just have easily used A-I instead of 1-9.\n",
    "\n",
    "**Quantitative Data** – This one is pretty easy if you remember that you can do math on a quantitative variable. Its is always a number. It can be my height, my weight, my pulse rate, the money in my checking account, my shoe size. If I have population or sample of these items \n",
    "I can average them, get a standard deviation etc. The word quantitative has a root of quantity, that should help you remember it.\n",
    "\n",
    "To go a little bit deeper into the rabbit whole there are two types of Quantitative data, I know, I’m sorry... Hopefully looking at the root word of each will help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quantitative Discreet** – Counting data. They ask How Many? How many people on a bus?\n",
    "\n",
    "- There are 20 people on the bus, not 19.5 or 20.5.\n",
    "\n",
    "How many cars in my driveway?\n",
    "- There are 2 cars in my driveway and one in the yard, though most of that on is missing it is still one car.\n",
    "\n",
    "How many books do you own?\n",
    "- I own 100 books, not 99.5, though an argument could be made for owning half a book, it is still one registered ISBN even if you do not have all of the book.\n",
    "\n",
    "How many emails did you get to day? \n",
    "- I received 50 emails today.\n",
    "\n",
    "Quantitative Continuous – Measuring data, this asks How Much?\n",
    "- What is your height?\n",
    "- What is your weight?\n",
    "- What is the weight of a vehicle? What iS the MPG of a vehicle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANGE AND IQR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next topics (Range, IQR, Variance and Standard Deviation) took up a combined 120 power point slides in my stats class, which means that describing all in a single post will not happen, and maybe two posts minimum, but I will try to keep it under 120 slides or pages.\n",
    "So, range, IQR (Interquartile Range), variance and standard deviation fall under summary measures as ways to describe numerical data.\n",
    "\n",
    "**Range** – is the measure of dispersion or spread. Using central tendency methods we can see where most of the data is piled up, but what do we know about the variability of the data? The range of the data is basically the maximum value – the minimum value.\n",
    "What to know about range? It is sensitive to outliers. It is unconcerned about the distribution of the data in the set.\n",
    "\n",
    "For instance, if I had a hybrid car in my mtcars dataset that achieved 120 mpg by the petrol standards set forth by the EPA, my range for mpg would be 10.40mpg to 120mpg. If I told you the cars in my sample had a mpg range of 10.40mpg to 120mpg what would you think of the cars? What range fails to disclose is that the next highest mpg car is 33.9, that’s pretty far away and not all representative of the true dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interquartile Range** – since we have already discussed quartiles this one is easy, the inter-quartile-range is simply the middle 50%, the values that reside between the 1st quartile(25%) and the first 3rd(75%) quartile. Summary() and favstats will give us the min(0%), Q1, Q2, Q3, max (100%)as will quantile()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IQRs help us find Outlier which is an observation point that is distant from other observations. An outlier may be due to variability in the measurement or it may indicate experimental error; the latter are sometimes excluded from the data set.\n",
    "\n",
    "One of the techniques for removing outliers is to use the IQR to isolate the center 50% of the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VARIANCE AND STANDARD DEVIATION\n",
    "\n",
    "It is said by some that standard deviation and variance are tedious to calcu- late by hand, I would agree with that but it is likely you will never ever do any of this by hand. That was more likely the stats of years gone by. But, in R you only have to know two commands to achieve standard deviation and variance, sd() and var(). Bam we are done! Okay one more, in SQL Server the commands are stdev and var! Bam, we are done!\n",
    "\n",
    "Fine! Here is my frustration with all of this, exactly what is it? My intro to stats class took 50 slides for this part and only two of them made sense, the two with words, the other 48 were an x,y grid, not helpful at all.\n",
    "\n",
    "Variance is the expected value of the squared deviation of a random vari- able for its mean. Looking at the R formula is easier. Variance = sum((x – mean(x)) ^2 ) / (length(x)-1). Work your way from the inside of the formula out of you need to.\n",
    "Standard deviation is a measure of the variation of dispersion of the data. This has a nice easy formula as well, and it is based on variance. Standard Deviation = sqrt(sum((x – mean(x)) ^2 ) / (length(x)-1)). It’s the square root of the variance, how cool is that, you only need to know one formula!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CENTRAL TENDENCY\n",
    "\n",
    "We have determined that quantitative data is essentially numeric data, or “measuring data”. Quantitative data asks how much. Knowing that, we can start to look at statistical techniques to analyze this data. To do this we will need to get some definitions out of the way, and some demonstrations to help figure out what these things are. None of them are derived from magic, though sometimes they certainly appear that way.\n",
    "\n",
    "There is a thing called central tendency, or the measure of central tendency. It is not very hard to derive the definition from the words, it is the tendency of the things to be centered, or the center or location of the distribution of data. For the most part, as the dataset we are using increases in size, it tends to have much of the data centered in a specific location. We measure this by using mean, median, and mode. To be clear, Mean, Mode, Median are all measurers of central tendency.\n",
    "\n",
    "Central Tendency will be one of the very important foundations of predic- tion, it’s a principle that assumes all of the data will be within a certain dis- tribution vs data all over the place. If you were to use a histogram with many bins, the data would be mound shaped. That mound means that we can prob- ably predict other new data based on certain factors, those factors will come later.\n",
    "\n",
    "**Mean** – the mean is the average, sum the data and divide by the number of values.\n",
    "\n",
    "**Median** is the middle number in the data set, using (1,2,3,4,5,6,6,7) we have eight numbers in the dataset, an even number, so we take the two middle numbers add them and divide by two, in this case the Median is 4.5. In R you can run median(c(1,2,3,4,5,6,6,7)). If we had an odd number of values in the dataset as in (1,1,1,2,9,9,9), “2” is the median. It is just the middle number.\n",
    "\n",
    "**Mode** is the number that shows up most often in the dataset. Mode is a little tricky, there is no built in function for Mode in base R. Stack overflow has a nice mode reference here, which demonstrates the following\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Percentile** - In statitistics a percentile is the measure indicating the value be- low which observations in a group fall. Yeah right, lets use an example. When occupy Wallstreet was all the rage they frequently help signs of 99%, that meant that you and i are the 99 percentile of income. Hence they were attempting to annoy anyone in the US who fell into the 1 percentile. According to an old article from investopedia, you would need to make more than 456,626 dollars AGI to be in the one percent. From that we can determine that any- one who makes less than 456,626 dollars AGI is in the 99 percentile. To be in the 95 percentile you need to make less than 214,462 dollars AGI per year. So, percentile is a measure of location. Where am i? Where are you?\n",
    "\n",
    "**Quartiles** - In descriptive statistics, the quartiles of a ranked set of data val- ues are the three points that divide the data set into four equal groups, each group comprising a quarter of the data. Clear as mud, well four equal groups makes sense. They are, 25%, 50%, 75%, these divide the data into four groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Empirical rule** states that;\n",
    "\n",
    "- 68% of the data will fall with in 1 standard deviation of the mean, \n",
    "- 95% of the data will fall within 2 standard deviations of the mean, and \n",
    "- 99.7% of the data will fall within 3 standard deviations of them mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chebyshevs**  rule, theorem, inequality, whatever you want to call it states that all possible datasets regardless of shape will have 75% of the data within 2 standard deviations, and 88.89% within 3 standard deviations. This should apply to mound shaped datasets as well as bimodal (two mounds) and multimodal (many mounds).\n",
    "The Chebyshevs rule states that;\n",
    "\n",
    "- 75% of the data will fall within 2 standard deviations of the mean, and \n",
    "- 88.89% of the data will fall within 3 standard deviations of them mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORRELATIONS AND COLLINEARITY\n",
    "\n",
    "\n",
    "All of the work we do in statistical learning is based on the fact we can predict y based on x. If i eat 10,000(x) calories a day i will be fat(y) unless i am an Olympic swimmer apparently, so it does not always hold true, but with just one dependent and one independent variable, it would appear to be an easy answer. Now if i added physical activity to the mix, fat or not fat might be more accurate. Every now and then you will hear about a “study” that some new claim is made from, and the world falls apart for a few days talking about nothing else. My recent favorite news story is diet soda makes you fat, gives you cardiovascular disease, hypertension, metabolic syndrome and type II diabetes. Whether you believe that or not, and for the sake of argument the article does not mention level of activity per day, calories of food consumed per day, you know, lots of other stuff that could contribute. The study appears to make the claim that diet soda all by itself will cause all of these health problems. Peter Attia has started to write about the problems with these studies and the problems with them.\n",
    "\n",
    "In short, an **observational** study means you are just watching and asking questions, not influencing, no treatment, no control. An observational study cannot be used to determine cause, you have surely heard correlation does not imply causation, this is never more true than in observational studies, and even more so for retrospective observational study, where you basically look at data from a prior observational study. You can find stuff, but you cannot conclude cause. Don’t get me wrong they are needed an necessary for research to move forward, but causation cannot be determined from this.\n",
    "\n",
    "Which brings me to these fun little anomalies;\n",
    "\n",
    "**Spurious correlations** are a hoot and a half. Spurious correlations is a mathematical relationship in which two or more events or variables are not causally related to each other, yet it may be wrongly inferred that they are. I can assure you that Nicolas Cage movies and pool drownings actually have nothing to do with each other but they do correlate.\n",
    "\n",
    "**Confounding and/or Lurking variable**; i see these used interchangeably, so it is a bit difficult to separate them. That being said, it is a variable that correlates to the dependent and independent variable thus influencing the significance, if one is detected, it should be removed. You will typically see this by two variables that always trend together though they actually have no direct impact on each other, they just happen to trend together. There is a great alternative example here, http://www.tylervigen.com/spurious-correlations\n",
    "\n",
    "**Collinearity or Multicollinearity** ; I’m totally copying the definition from PSU, they have great stuff btw; “when it exists, it can wreak havoc on our analysis and thereby limit the research conclusions we can draw”, “multicollinearity exists whenever two or more of the predictors in a regression model are moderately or highly correlated” In R you have to go slightly out of your way to determine collinearity using VIF, variation inflation factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
