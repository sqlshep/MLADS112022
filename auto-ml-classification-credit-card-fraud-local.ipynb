{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Machine Learning\n",
    "_**Classification of credit card fraudulent transactions with local run **_\n",
    "\n",
    "## Contents\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Setup](#Setup)\n",
    "1. [Train](#Train)\n",
    "1. [Results](#Results)\n",
    "1. [Test](#Tests)\n",
    "1. [Explanation](#Explanation)\n",
    "1. [Acknowledgements](#Acknowledgements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this example we use the associated credit card dataset to showcase how you can use AutoML for a simple classification problem. The goal is to predict if a credit card transaction is considered a fraudulent charge.\n",
    "\n",
    "This notebook is using the local machine compute to train the model.\n",
    "\n",
    "If you are using an Azure Machine Learning Compute Instance, you are all set. Otherwise, go through the [configuration](../../../configuration.ipynb) notebook first if you haven't already to establish your connection to the AzureML Workspace. \n",
    "\n",
    "In this notebook you will learn how to:\n",
    "1. Create an experiment using an existing workspace.\n",
    "2. Configure AutoML using `AutoMLConfig`.\n",
    "3. Train the model.\n",
    "4. Explore the results.\n",
    "5. Test the fitted model.\n",
    "6. Explore any model's explanation and explore feature importance in azure portal.\n",
    "7. Create an AKS cluster, deploy the webservice of AutoML scoring model and the explainer model to the AKS and consume the web service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As part of the setup you have already created an Azure ML `Workspace` object. For Automated ML you will need to create an `Experiment` object, which is a named object in a `Workspace` used to run experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1646937833272
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.interpret import ExplanationClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample notebook may use features that are not available in previous versions of the Azure ML SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1646937842000
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subscription ID</th>\n",
       "      <td>d83b98a9-eaa6-475f-9ae6-1ef35394a1e5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Workspace</th>\n",
       "      <td>shepml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>rg-ml-workspace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>eastus2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment Name</th>\n",
       "      <td>automl-classification-ccard-local</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     \n",
       "Subscription ID  d83b98a9-eaa6-475f-9ae6-1ef35394a1e5\n",
       "Workspace        shepml                              \n",
       "Resource Group   rg-ml-workspace                     \n",
       "Location         eastus2                             \n",
       "Experiment Name  automl-classification-ccard-local   "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# choose a name for experiment\n",
    "experiment_name = \"automl-classification-ccard-local\"\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "output = {}\n",
    "output[\"Subscription ID\"] = ws.subscription_id\n",
    "output[\"Workspace\"] = ws.name\n",
    "output[\"Resource Group\"] = ws.resource_group\n",
    "output[\"Location\"] = ws.location\n",
    "output[\"Experiment Name\"] = experiment.name\n",
    "pd.set_option(\"display.max_colwidth\", -1)\n",
    "outputDf = pd.DataFrame(data=output, index=[\"\"])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "Load the credit card dataset from a csv file containing both training features and labels. The features are inputs to the model, while the training labels represent the expected output of the model. Next, we'll split the data using random_split and extract the training data for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1646937855040
    }
   },
   "outputs": [],
   "source": [
    "data = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/creditcard.csv\"\n",
    "dataset = Dataset.Tabular.from_delimited_files(data)\n",
    "training_data, validation_data = dataset.random_split(percentage=0.8, seed=223)\n",
    "label_column_name = \"Class\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Instantiate a AutoMLConfig object. This defines the settings and data used to run the experiment.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**task**|classification or regression|\n",
    "|**primary_metric**|This is the metric that you want to optimize. Classification supports the following primary metrics: <br><i>accuracy</i><br><i>AUC_weighted</i><br><i>average_precision_score_weighted</i><br><i>norm_macro_recall</i><br><i>precision_score_weighted</i>|\n",
    "|**enable_early_stopping**|Stop the run if the metric score is not showing improvement.|\n",
    "|**n_cross_validations**|Number of cross validation splits.|\n",
    "|**training_data**|Input dataset, containing both features and label column.|\n",
    "|**label_column_name**|The name of the label column.|\n",
    "\n",
    "**_You can find more information about primary metrics_** [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train#primary-metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1646937856830
    },
    "name": "enable-ensemble"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No run_configuration provided, running on local with default configuration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27:14:24:13,411 INFO     [modeling_bert.py:226] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "2022-10-27:14:24:13,426 INFO     [modeling_xlnet.py:339] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "2022-10-27:14:24:19,770 INFO     [utils.py:159] NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in the active local environment.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl-classification-ccard-local</td><td>AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00</td><td>automl</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00?wsid=/subscriptions/d83b98a9-eaa6-475f-9ae6-1ef35394a1e5/resourcegroups/rg-ml-workspace/workspaces/shepml&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\n",
      "Current status: DatasetBalancing. Performing class balancing sweeping\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "\n",
      "********************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       ALERTED\n",
      "DESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "DETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n",
      "+------------------------------+--------------------------------+--------------------------------------+\n",
      "|Size of the smallest class    |Name/Label of the smallest class|Number of samples in the training data|\n",
      "+==============================+================================+======================================+\n",
      "|349                           |True                            |199505                                |\n",
      "+------------------------------+--------------------------------+--------------------------------------+\n",
      "\n",
      "********************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       DONE\n",
      "DESCRIPTION:  If the missing values are expected, let the run complete. Otherwise cancel the current run and use a script to customize the handling of missing feature values that may be more appropriate based on the data type and business requirement.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "DETAILS:      \n",
      "+------------------------------+------------------------------+------------------------------+\n",
      "|Column name                   |Missing value count           |Imputation type               |\n",
      "+==============================+==============================+==============================+\n",
      "|Time                          |1                             |mean                          |\n",
      "+------------------------------+------------------------------+------------------------------+\n",
      "\n",
      "********************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "********************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "********************************************************************************************\n",
      "ITER: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "********************************************************************************************\n",
      "\n",
      " ITER   PIPELINE                                       DURATION            METRIC      BEST\n",
      "    0   MaxAbsScaler LightGBM                          0:00:50             0.9966    0.9966\n",
      "    1   MaxAbsScaler XGBoostClassifier                 0:03:06             0.9996    0.9996\n",
      "    2   MaxAbsScaler ExtremeRandomTrees                0:00:54             0.9994    0.9996\n",
      "    3   SparseNormalizer XGBoostClassifier             0:00:49             0.9992    0.9996\n",
      "    4   MaxAbsScaler LightGBM                          0:00:37             0.9994    0.9996\n",
      "    5   MaxAbsScaler LogisticRegression                0:00:55             0.9995    0.9996\n",
      "    6   SparseNormalizer XGBoostClassifier             0:00:58             0.9993    0.9996\n",
      "    7   StandardScalerWrapper LogisticRegression       0:00:55             0.9995    0.9996\n",
      "    8   MaxAbsScaler ExtremeRandomTrees                0:01:11             0.9993    0.9996\n",
      "    9   StandardScalerWrapper ExtremeRandomTrees       0:00:40             0.9993    0.9996\n",
      "   10   MaxAbsScaler LightGBM                          0:00:41             0.9994    0.9996\n",
      "   11   StandardScalerWrapper XGBoostClassifier        0:00:55             0.9995    0.9996\n",
      "   12   StandardScalerWrapper LogisticRegression       0:01:27             0.9994    0.9996\n",
      "   13   VotingEnsemble                                 0:01:01             0.9997    0.9997\n",
      "Stopping criteria reached at iteration 14. Ending experiment.\n",
      "********************************************************************************************\n",
      "Current status: BestRunExplainModel. Best run model explanations started\n",
      "Current status: ModelExplanationDataSetSetup. Model explanations data setup completed\n",
      "Current status: PickSurrogateModel. Choosing LightGBM as the surrogate model for explanations\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27:14:42:56,730 INFO     [explanation_client.py:334] Using default datastore for uploads\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: EngineeredFeatureExplanations. Computation of engineered features completed\n",
      "Current status: RawFeaturesExplanations. Computation of raw features started\n",
      "Current status: RawFeaturesExplanations. Computation of raw features completed\n",
      "Current status: BestRunExplainModel. Best run model explanations completed\n",
      "********************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "data = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/creditcard.csv\"\n",
    "dataset = Dataset.Tabular.from_delimited_files(data)\n",
    "training_data, validation_data = dataset.random_split(percentage=0.7)\n",
    "label_column_name = \"Class\"\n",
    "\n",
    "automl_settings = {\n",
    "    \"n_cross_validations\": 3, #Number of cross validation splits.\n",
    "    \"primary_metric\": \"average_precision_score_weighted\", #This is the metric that you want to optimize.\n",
    "    \"experiment_timeout_hours\": 0.25, #percentage of an hour you want this to run\n",
    "    \"verbosity\": logging.INFO, #logging info level, debug, info, warning, error, critical \n",
    "    \"enable_stack_ensemble\": False, # VotingEnsembled is enabled by defualt\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(\n",
    "    task=\"classification\",\n",
    "    debug_log=\"automl_errors.log\",\n",
    "    training_data=training_data,\n",
    "    label_column_name=label_column_name,\n",
    "    **automl_settings,\n",
    ")\n",
    "\n",
    "local_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the `submit` method on the experiment object and pass the run configuration. Depending on the data and the number of iterations this can run for a while.\n",
    "In this example, we specify `show_output = True` to print currently running iterations to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1646938961233
    }
   },
   "outputs": [],
   "source": [
    "#local_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to retrieve a run that already started, use the following code\n",
    "# from azureml.train.automl.run import AutoMLRun\n",
    "# local_run = AutoMLRun(experiment = experiment, run_id = '<replace with your run id>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Widget for Monitoring Runs\n",
    "\n",
    "The widget will first report a \"loading\" status while running the first iteration. After completing the first iteration, an auto-updating graph and table will be shown. The widget will refresh once per minute, so you should see the graph update as child runs complete.\n",
    "\n",
    "**Note:** The widget displays a link at the bottom. Use this link to open a web interface to explore the individual run details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1646938961502
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10424f36475e46e99bd8650037561a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00?wsid=/subscriptions/d83b98a9-eaa6-475f-9ae6-1ef35394a1e5/resourcegroups/rg-ml-workspace/workspaces/shepml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"run_properties\": {\"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"created_utc\": \"2022-10-27T14:24:29.760258Z\", \"properties\": {\"num_iterations\": \"1000\", \"training_type\": \"TrainFull\", \"acquisition_function\": \"EI\", \"primary_metric\": \"average_precision_score_weighted\", \"train_split\": \"0\", \"acquisition_parameter\": \"0\", \"num_cross_validation\": \"3\", \"target\": \"local\", \"AMLSettingsJsonString\": \"{\\\"path\\\":null,\\\"name\\\":\\\"automl-classification-ccard-local\\\",\\\"subscription_id\\\":\\\"d83b98a9-eaa6-475f-9ae6-1ef35394a1e5\\\",\\\"resource_group\\\":\\\"rg-ml-workspace\\\",\\\"workspace_name\\\":\\\"shepml\\\",\\\"region\\\":\\\"eastus2\\\",\\\"compute_target\\\":\\\"local\\\",\\\"spark_service\\\":null,\\\"azure_service\\\":\\\"Microsoft.AzureNotebookVM\\\",\\\"many_models\\\":false,\\\"pipeline_fetch_max_batch_size\\\":1,\\\"enable_batch_run\\\":false,\\\"enable_run_restructure\\\":false,\\\"start_auxiliary_runs_before_parent_complete\\\":false,\\\"enable_code_generation\\\":false,\\\"iterations\\\":1000,\\\"primary_metric\\\":\\\"average_precision_score_weighted\\\",\\\"task_type\\\":\\\"classification\\\",\\\"positive_label\\\":null,\\\"data_script\\\":null,\\\"test_size\\\":0.0,\\\"test_include_predictions_only\\\":false,\\\"validation_size\\\":0.0,\\\"n_cross_validations\\\":3,\\\"y_min\\\":null,\\\"y_max\\\":null,\\\"num_classes\\\":null,\\\"featurization\\\":\\\"auto\\\",\\\"_ignore_package_version_incompatibilities\\\":false,\\\"is_timeseries\\\":false,\\\"max_cores_per_iteration\\\":1,\\\"max_concurrent_iterations\\\":1,\\\"iteration_timeout_minutes\\\":null,\\\"mem_in_mb\\\":null,\\\"enforce_time_on_windows\\\":false,\\\"experiment_timeout_minutes\\\":15,\\\"experiment_exit_score\\\":null,\\\"whitelist_models\\\":null,\\\"blacklist_algos\\\":[\\\"TensorFlowLinearClassifier\\\",\\\"TensorFlowDNN\\\"],\\\"supported_models\\\":[\\\"TensorFlowLinearClassifier\\\",\\\"LogisticRegression\\\",\\\"TabnetClassifier\\\",\\\"BernoulliNaiveBayes\\\",\\\"RandomForest\\\",\\\"ExtremeRandomTrees\\\",\\\"LinearSVM\\\",\\\"MultinomialNaiveBayes\\\",\\\"DecisionTree\\\",\\\"LightGBM\\\",\\\"AveragedPerceptronClassifier\\\",\\\"TensorFlowDNN\\\",\\\"XGBoostClassifier\\\",\\\"KNN\\\",\\\"GradientBoosting\\\",\\\"SVM\\\",\\\"SGD\\\"],\\\"private_models\\\":[],\\\"auto_blacklist\\\":true,\\\"blacklist_samples_reached\\\":false,\\\"exclude_nan_labels\\\":true,\\\"verbosity\\\":20,\\\"_debug_log\\\":\\\"automl_errors.log\\\",\\\"show_warnings\\\":false,\\\"model_explainability\\\":true,\\\"service_url\\\":null,\\\"sdk_url\\\":null,\\\"sdk_packages\\\":null,\\\"enable_onnx_compatible_models\\\":false,\\\"enable_split_onnx_featurizer_estimator_models\\\":false,\\\"vm_type\\\":null,\\\"telemetry_verbosity\\\":20,\\\"send_telemetry\\\":true,\\\"enable_dnn\\\":false,\\\"scenario\\\":\\\"SDK-1.13.0\\\",\\\"environment_label\\\":null,\\\"save_mlflow\\\":false,\\\"enable_categorical_indicators\\\":false,\\\"force_text_dnn\\\":false,\\\"enable_feature_sweeping\\\":true,\\\"enable_early_stopping\\\":true,\\\"early_stopping_n_iters\\\":10,\\\"arguments\\\":null,\\\"dataset_id\\\":\\\"06736e20-5886-4555-ae93-a816a2e059ce\\\",\\\"hyperdrive_config\\\":null,\\\"validation_dataset_id\\\":null,\\\"run_source\\\":null,\\\"metrics\\\":null,\\\"enable_metric_confidence\\\":false,\\\"enable_ensembling\\\":true,\\\"enable_stack_ensembling\\\":false,\\\"ensemble_iterations\\\":15,\\\"enable_tf\\\":false,\\\"enable_subsampling\\\":null,\\\"subsample_seed\\\":null,\\\"enable_nimbusml\\\":false,\\\"enable_streaming\\\":false,\\\"force_streaming\\\":false,\\\"track_child_runs\\\":true,\\\"allowed_private_models\\\":[],\\\"label_column_name\\\":\\\"Class\\\",\\\"weight_column_name\\\":null,\\\"cv_split_column_names\\\":null,\\\"enable_local_managed\\\":false,\\\"_local_managed_run_id\\\":null,\\\"cost_mode\\\":1,\\\"lag_length\\\":0,\\\"metric_operation\\\":\\\"maximize\\\",\\\"preprocess\\\":true}\", \"DataPrepJsonString\": \"{\\\\\\\"training_data\\\\\\\": {\\\\\\\"datasetId\\\\\\\": \\\\\\\"06736e20-5886-4555-ae93-a816a2e059ce\\\\\\\"}, \\\\\\\"datasets\\\\\\\": 0}\", \"EnableSubsampling\": null, \"runTemplate\": \"AutoML\", \"azureml.runsource\": \"automl\", \"display_task_type\": \"classification\", \"dependencies_versions\": \"{\\\"azureml-widgets\\\": \\\"1.38.0\\\", \\\"azureml-train\\\": \\\"1.38.0\\\", \\\"azureml-train-restclients-hyperdrive\\\": \\\"1.38.0\\\", \\\"azureml-train-core\\\": \\\"1.38.0\\\", \\\"azureml-train-automl\\\": \\\"1.38.0\\\", \\\"azureml-train-automl-runtime\\\": \\\"1.38.0\\\", \\\"azureml-train-automl-client\\\": \\\"1.38.0\\\", \\\"azureml-tensorboard\\\": \\\"1.38.0\\\", \\\"azureml-telemetry\\\": \\\"1.38.0\\\", \\\"azureml-sdk\\\": \\\"1.38.0\\\", \\\"azureml-responsibleai\\\": \\\"1.38.0\\\", \\\"azureml-pipeline\\\": \\\"1.38.0\\\", \\\"azureml-pipeline-steps\\\": \\\"1.38.0\\\", \\\"azureml-pipeline-core\\\": \\\"1.38.0\\\", \\\"azureml-opendatasets\\\": \\\"1.38.0\\\", \\\"azureml-mlflow\\\": \\\"1.38.0\\\", \\\"azureml-interpret\\\": \\\"1.38.0\\\", \\\"azureml-inference-server-http\\\": \\\"0.4.2\\\", \\\"azureml-explain-model\\\": \\\"1.38.0\\\", \\\"azureml-defaults\\\": \\\"1.38.0\\\", \\\"azureml-dataset-runtime\\\": \\\"1.38.0\\\", \\\"azureml-dataprep\\\": \\\"2.26.0\\\", \\\"azureml-dataprep-rslex\\\": \\\"2.2.0\\\", \\\"azureml-dataprep-native\\\": \\\"38.0.0\\\", \\\"azureml-datadrift\\\": \\\"1.38.0\\\", \\\"azureml-core\\\": \\\"1.38.0\\\", \\\"azureml-contrib-services\\\": \\\"1.38.0\\\", \\\"azureml-contrib-server\\\": \\\"1.38.0\\\", \\\"azureml-contrib-reinforcementlearning\\\": \\\"1.38.0\\\", \\\"azureml-contrib-pipeline-steps\\\": \\\"1.38.0\\\", \\\"azureml-contrib-notebook\\\": \\\"1.38.0\\\", \\\"azureml-contrib-fairness\\\": \\\"1.38.0\\\", \\\"azureml-contrib-dataset\\\": \\\"1.38.0\\\", \\\"azureml-contrib-automl-pipeline-steps\\\": \\\"1.38.0\\\", \\\"azureml-cli-common\\\": \\\"1.38.0\\\", \\\"azureml-automl-runtime\\\": \\\"1.38.0\\\", \\\"azureml-automl-dnn-nlp\\\": \\\"1.38.0\\\", \\\"azureml-automl-core\\\": \\\"1.38.0\\\", \\\"azureml-accel-models\\\": \\\"1.38.0\\\"}\", \"_aml_system_scenario_identification\": \"Local.Parent\", \"ClientSdkVersion\": \"1.38.0\", \"ClientType\": \"SDK\", \"environment_cpu_name\": \"AzureML-AutoML\", \"environment_cpu_label\": \"py36\", \"environment_gpu_name\": \"AzureML-AutoML-GPU\", \"environment_gpu_label\": \"py36\", \"root_attribution\": \"automl\", \"attribution\": \"AutoML\", \"Orchestrator\": \"AutoML\", \"_azureml.ComputeTargetType\": \"local\", \"ProblemInfoJsonString\": \"{\\\"dataset_num_categorical\\\": 0, \\\"is_sparse\\\": false, \\\"subsampling\\\": false, \\\"has_extra_col\\\": true, \\\"dataset_classes\\\": 2, \\\"dataset_features\\\": 30, \\\"dataset_samples\\\": 199505, \\\"single_frequency_class_detected\\\": false}\"}, \"tags\": {\"model_explain_run\": \"best_run\", \"_aml_system_automl_run_workspace_id\": \"159e7260-d6e4-4d6a-88cf-34c1a4bd15ee\", \"best_score\": \"0.9996831872845306\", \"best_pipeline\": \"VotingEnsemble\", \"automl_best_child_run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_13\", \"model_explain_best_run_child_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_13\"}, \"end_time_utc\": \"2022-10-27T14:40:49.682947Z\", \"status\": \"Completed\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:16:19\", \"run_number\": \"1666880669\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_0\", \"run_number\": 1666880729, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-10-27T14:25:29.969287Z\", \"end_time\": \"2022-10-27T14:26:20.504608Z\", \"created_time\": \"2022-10-27T14:25:29.8853Z\", \"created_time_dt\": \"2022-10-27T14:25:29.8853Z\", \"duration\": \"0:00:50\", \"iteration\": \"0\", \"goal\": \"average_precision_score_weighted_max\", \"run_name\": \"MaxAbsScaler, LightGBM\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.99656668, \"best_metric\": 0.99656668}, {\"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_1\", \"run_number\": 1666880780, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-10-27T14:26:20.852524Z\", \"end_time\": \"2022-10-27T14:29:27.130025Z\", \"created_time\": \"2022-10-27T14:26:20.725581Z\", \"created_time_dt\": \"2022-10-27T14:26:20.725581Z\", \"duration\": \"0:03:06\", \"iteration\": \"1\", \"goal\": \"average_precision_score_weighted_max\", \"run_name\": \"MaxAbsScaler, XGBoostClassifier\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.99963577, \"best_metric\": 0.99963577}, {\"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_2\", \"run_number\": 1666880967, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-10-27T14:29:27.80312Z\", \"end_time\": \"2022-10-27T14:30:22.035582Z\", \"created_time\": \"2022-10-27T14:29:27.759348Z\", \"created_time_dt\": \"2022-10-27T14:29:27.759348Z\", \"duration\": \"0:00:54\", \"iteration\": \"2\", \"goal\": \"average_precision_score_weighted_max\", \"run_name\": \"MaxAbsScaler, ExtremeRandomTrees\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.99935612, \"best_metric\": 0.99963577}, {\"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_3\", \"run_number\": 1666881023, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-10-27T14:30:23.310595Z\", \"end_time\": \"2022-10-27T14:31:13.020787Z\", \"created_time\": \"2022-10-27T14:30:23.310595Z\", \"created_time_dt\": \"2022-10-27T14:30:23.310595Z\", \"duration\": \"0:00:49\", \"iteration\": \"3\", \"goal\": \"average_precision_score_weighted_max\", \"run_name\": \"SparseNormalizer, XGBoostClassifier\", \"run_properties\": \"copy=True, norm='l2'\", \"primary_metric\": 0.99915866, \"best_metric\": 0.99963577}, {\"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_4\", \"run_number\": 1666881074, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-10-27T14:31:14.215207Z\", \"end_time\": \"2022-10-27T14:31:51.824556Z\", \"created_time\": \"2022-10-27T14:31:14.194958Z\", \"created_time_dt\": \"2022-10-27T14:31:14.194958Z\", \"duration\": \"0:00:37\", \"iteration\": \"4\", \"goal\": \"average_precision_score_weighted_max\", \"run_name\": \"MaxAbsScaler, LightGBM\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.99937292, \"best_metric\": 0.99963577}, {\"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_5\", \"run_number\": 1666881113, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-10-27T14:31:53.117995Z\", \"end_time\": \"2022-10-27T14:32:48.967467Z\", \"created_time\": \"2022-10-27T14:31:53.117995Z\", \"created_time_dt\": \"2022-10-27T14:31:53.117995Z\", \"duration\": \"0:00:55\", \"iteration\": \"5\", \"goal\": \"average_precision_score_weighted_max\", \"run_name\": \"MaxAbsScaler, LogisticRegression\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.99945873, \"best_metric\": 0.99963577}, {\"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_6\", \"run_number\": 1666881170, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-10-27T14:32:50.333966Z\", \"end_time\": \"2022-10-27T14:33:48.429177Z\", \"created_time\": \"2022-10-27T14:32:50.248572Z\", \"created_time_dt\": \"2022-10-27T14:32:50.248572Z\", \"duration\": \"0:00:58\", \"iteration\": \"6\", \"goal\": \"average_precision_score_weighted_max\", \"run_name\": \"SparseNormalizer, XGBoostClassifier\", \"run_properties\": \"copy=True, norm='max'\", \"primary_metric\": 0.99929734, \"best_metric\": 0.99963577}, {\"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_7\", \"run_number\": 1666881229, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-10-27T14:33:49.65634Z\", \"end_time\": \"2022-10-27T14:34:44.746872Z\", \"created_time\": \"2022-10-27T14:33:49.560448Z\", \"created_time_dt\": \"2022-10-27T14:33:49.560448Z\", \"duration\": \"0:00:55\", \"iteration\": \"7\", \"goal\": \"average_precision_score_weighted_max\", \"run_name\": \"StandardScalerWrapper, LogisticRegression\", \"run_properties\": \"\\n    copy=True,\\n    with_mean=True,\\n    with_std=False\\n\", \"primary_metric\": 0.99950278, \"best_metric\": 0.99963577}, {\"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_8\", \"run_number\": 1666881286, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-10-27T14:34:46.073248Z\", \"end_time\": \"2022-10-27T14:35:57.64642Z\", \"created_time\": \"2022-10-27T14:34:46.016742Z\", \"created_time_dt\": \"2022-10-27T14:34:46.016742Z\", \"duration\": \"0:01:11\", \"iteration\": \"8\", \"goal\": \"average_precision_score_weighted_max\", \"run_name\": \"MaxAbsScaler, ExtremeRandomTrees\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.99932788, \"best_metric\": 0.99963577}, {\"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_9\", \"run_number\": 1666881358, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-10-27T14:35:58.851562Z\", \"end_time\": \"2022-10-27T14:36:39.562073Z\", \"created_time\": \"2022-10-27T14:35:58.71473Z\", \"created_time_dt\": \"2022-10-27T14:35:58.71473Z\", \"duration\": \"0:00:40\", \"iteration\": \"9\", \"goal\": \"average_precision_score_weighted_max\", \"run_name\": \"StandardScalerWrapper, ExtremeRandomTrees\", \"run_properties\": \"\\n    copy=True,\\n    with_mean=True,\\n    with_std=True\\n\", \"primary_metric\": 0.99931301, \"best_metric\": 0.99963577}, {\"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_10\", \"run_number\": 1666881400, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-10-27T14:36:40.849048Z\", \"end_time\": \"2022-10-27T14:37:22.147242Z\", \"created_time\": \"2022-10-27T14:36:40.713524Z\", \"created_time_dt\": \"2022-10-27T14:36:40.713524Z\", \"duration\": \"0:00:41\", \"iteration\": \"10\", \"goal\": \"average_precision_score_weighted_max\", \"run_name\": \"MaxAbsScaler, LightGBM\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.9994226, \"best_metric\": 0.99963577}, {\"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_11\", \"run_number\": 1666881443, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-10-27T14:37:23.437571Z\", \"end_time\": \"2022-10-27T14:38:19.302982Z\", \"created_time\": \"2022-10-27T14:37:23.271284Z\", \"created_time_dt\": \"2022-10-27T14:37:23.271284Z\", \"duration\": \"0:00:56\", \"iteration\": \"11\", \"goal\": \"average_precision_score_weighted_max\", \"run_name\": \"StandardScalerWrapper, XGBoostClassifier\", \"run_properties\": \"\\n    copy=True,\\n    with_mean=False,\\n    with_std=False\\n\", \"primary_metric\": 0.99945397, \"best_metric\": 0.99963577}, {\"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_12\", \"run_number\": 1666881500, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-10-27T14:38:20.556512Z\", \"end_time\": \"2022-10-27T14:39:47.962522Z\", \"created_time\": \"2022-10-27T14:38:20.51671Z\", \"created_time_dt\": \"2022-10-27T14:38:20.51671Z\", \"duration\": \"0:01:27\", \"iteration\": \"12\", \"goal\": \"average_precision_score_weighted_max\", \"run_name\": \"StandardScalerWrapper, LogisticRegression\", \"run_properties\": \"\\n    copy=True,\\n    with_mean=True,\\n    with_std=True\\n\", \"primary_metric\": 0.9994408, \"best_metric\": 0.99963577}, {\"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_13\", \"run_number\": 1666881588, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-10-27T14:39:48.303098Z\", \"end_time\": \"2022-10-27T14:40:49.272487Z\", \"created_time\": \"2022-10-27T14:39:48.226747Z\", \"created_time_dt\": \"2022-10-27T14:39:48.226747Z\", \"duration\": \"0:01:01\", \"iteration\": \"13\", \"goal\": \"average_precision_score_weighted_max\", \"run_name\": \"VotingEnsemble\", \"run_properties\": \"\\n    estimators=[('1', Pipeline(\\n        memory=None,\\n        steps=[('maxabsscaler', MaxAbsScaler(\\n            copy=True\\n        \", \"primary_metric\": 0.99968319, \"best_metric\": 0.99968319}], \"children_metrics\": {\"categories\": [0], \"series\": {\"balanced_accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"balanced_accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.5558157084874782, 0.8977023276528598, 0.9203329507593235, 0.7516169116897844, 0.5, 0.9408558508081238, 0.8023560462670777, 0.8055782538545581, 0.9218070790969132, 0.5, 0.8118221148468635, 0.8909306627987691, 0.9435628795768801, 0.8991596801842796]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"balanced_accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.5558157084874782, 0.8977023276528598, 0.9203329507593235, 0.9203329507593235, 0.9203329507593235, 0.9408558508081238, 0.9408558508081238, 0.9408558508081238, 0.9408558508081238, 0.9408558508081238, 0.9408558508081238, 0.9408558508081238, 0.9435628795768801, 0.9435628795768801]}], \"log_loss\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"log_loss\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.30649250307563825, 0.002734242990266226, 0.5330015688857412, 0.1996497287572312, 0.005914257894934262, 0.11034971700485487, 0.0431826460549421, 0.004295315092812995, 0.5493156129596416, 0.009977050799213094, 0.003815207710244162, 0.19866410029036663, 0.10999654370975721, 0.11458748092259456]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"log_loss_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.30649250307563825, 0.002734242990266226, 0.002734242990266226, 0.002734242990266226, 0.002734242990266226, 0.002734242990266226, 0.002734242990266226, 0.002734242990266226, 0.002734242990266226, 0.002734242990266226, 0.002734242990266226, 0.002734242990266226, 0.002734242990266226, 0.002734242990266226]}], \"norm_macro_recall\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"norm_macro_recall\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.11163141697495631, 0.7954046553057196, 0.840665901518647, 0.5032338233795687, 0.0, 0.8817117016162476, 0.6047120925341553, 0.6111565077091162, 0.8436141581938262, 0.0, 0.6236442296937269, 0.7818613255975381, 0.88712575915376, 0.7983193603685591]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"norm_macro_recall_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.11163141697495631, 0.7954046553057196, 0.840665901518647, 0.840665901518647, 0.840665901518647, 0.8817117016162476, 0.8817117016162476, 0.8817117016162476, 0.8817117016162476, 0.8817117016162476, 0.8817117016162476, 0.8817117016162476, 0.88712575915376, 0.88712575915376]}], \"average_precision_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"average_precision_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9862070045232993, 0.9998769060117848, 0.9983978907195432, 0.9995021013911445, 0.9998499392019967, 0.9915526918151344, 0.9995995987738037, 0.9995297433132707, 0.9983585089430324, 0.9998371709472784, 0.9998852002936776, 0.9996636058888054, 0.9916073007222742, 0.9999249986598199]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"average_precision_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9862070045232993, 0.9998769060117848, 0.9998769060117848, 0.9998769060117848, 0.9998769060117848, 0.9998769060117848, 0.9998769060117848, 0.9998769060117848, 0.9998769060117848, 0.9998769060117848, 0.9998852002936776, 0.9998852002936776, 0.9998852002936776, 0.9999249986598199]}], \"f1_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"f1_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9907320804195057, 0.9995438708045347, 0.9909425931680579, 0.9990676922374951, 0.9982506693037042, 0.9771885521916356, 0.9992381140063195, 0.9991629276946349, 0.9941104253826857, 0.9982506693037042, 0.9991529032349669, 0.9995087841404744, 0.9771183791650072, 0.9995137963703083]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"f1_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9907320804195057, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347]}], \"average_precision_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"average_precision_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9965666839700679, 0.9996357673927366, 0.9993561239285422, 0.9991586592119325, 0.9993729192212161, 0.999458727782231, 0.99929733561327, 0.9995027807210057, 0.9993278836354454, 0.9993130112365529, 0.9994226000671769, 0.9994539674849484, 0.9994407997031981, 0.9996831872845306]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"average_precision_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9965666839700679, 0.9996357673927366, 0.9996357673927366, 0.9996357673927366, 0.9996357673927366, 0.9996357673927366, 0.9996357673927366, 0.9996357673927366, 0.9996357673927366, 0.9996357673927366, 0.9996357673927366, 0.9996357673927366, 0.9996357673927366, 0.9996831872845306]}], \"f1_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"f1_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.5169141430209258, 0.9295023884680308, 0.6404423647235555, 0.826196016895441, 0.49956228112038675, 0.555375107942767, 0.8671745693867283, 0.8591571636121419, 0.6669271759800345, 0.49956228112038675, 0.8595929469527116, 0.9236747639779305, 0.5555685855277479, 0.9256996116910283]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"f1_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.5169141430209258, 0.9295023884680308, 0.9295023884680308, 0.9295023884680308, 0.9295023884680308, 0.9295023884680308, 0.9295023884680308, 0.9295023884680308, 0.9295023884680308, 0.9295023884680308, 0.9295023884680308, 0.9295023884680308, 0.9295023884680308, 0.9295023884680308]}], \"accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9907320804195057, 0.9995438708045347, 0.9909425931680579, 0.9990676922374951, 0.9982506693037042, 0.9771885521916356, 0.9992381140063195, 0.9991629276946349, 0.9941104253826857, 0.9982506693037042, 0.9991529032349669, 0.9995087841404744, 0.9771183791650072, 0.9995137963703083]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9907320804195057, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347]}], \"precision_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"precision_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.510936246590759, 0.9673198311192731, 0.5884679742998471, 0.9642751720604595, 0.4991253346518521, 0.5327591347938573, 0.9678650057109132, 0.9358633744945198, 0.6054317151927066, 0.4991253346518521, 0.9265706208687071, 0.9639388381910691, 0.532874117684141, 0.956613229815647]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"precision_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.510936246590759, 0.9673198311192731, 0.9673198311192731, 0.9673198311192731, 0.9673198311192731, 0.9673198311192731, 0.9678650057109132, 0.9678650057109132, 0.9678650057109132, 0.9678650057109132, 0.9678650057109132, 0.9678650057109132, 0.9678650057109132, 0.9678650057109132]}], \"AUC_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"AUC_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.5205207932632431, 0.9714295008838104, 0.9721145956593601, 0.9035184183736443, 0.9636612883110603, 0.978022560179696, 0.9222559353771799, 0.9822722631625892, 0.9723344484019208, 0.964132621530597, 0.9723156897772075, 0.9410135988804357, 0.9743033795006631, 0.9807643284478225]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"AUC_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.5205207932632431, 0.9714295008838104, 0.9721145956593601, 0.9721145956593601, 0.9721145956593601, 0.978022560179696, 0.978022560179696, 0.9822722631625892, 0.9822722631625892, 0.9822722631625892, 0.9822722631625892, 0.9822722631625892, 0.9822722631625892, 0.9822722631625892]}], \"recall_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"recall_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9907320804195057, 0.9995438708045347, 0.9909425931680579, 0.9990676922374951, 0.9982506693037042, 0.9771885521916356, 0.9992381140063195, 0.9991629276946349, 0.9941104253826857, 0.9982506693037042, 0.9991529032349669, 0.9995087841404744, 0.9771183791650072, 0.9995137963703083]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"recall_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9907320804195057, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347]}], \"precision_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"precision_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9907320804195057, 0.9995438708045347, 0.9909425931680579, 0.9990676922374951, 0.9982506693037042, 0.9771885521916356, 0.9992381140063195, 0.9991629276946349, 0.9941104253826857, 0.9982506693037042, 0.9991529032349669, 0.9995087841404744, 0.9771183791650072, 0.9995137963703083]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"precision_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9907320804195057, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347]}], \"AUC_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"AUC_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9901468126697649, 0.9998959711761035, 0.9990692277882407, 0.9996629647547479, 0.9998683014378845, 0.9938343699920454, 0.9997256169218353, 0.9998002145148649, 0.9993756070175678, 0.9998658222855278, 0.9998987575254846, 0.9997786357036421, 0.993818477358864, 0.9999275722047226]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"AUC_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9901468126697649, 0.9998959711761035, 0.9998959711761035, 0.9998959711761035, 0.9998959711761035, 0.9998959711761035, 0.9998959711761035, 0.9998959711761035, 0.9998959711761035, 0.9998959711761035, 0.9998987575254846, 0.9998987575254846, 0.9998987575254846, 0.9999275722047226]}], \"precision_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"precision_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9967261726718165, 0.9995283433012266, 0.9982986769959487, 0.9990145674300402, 0.9965044255015413, 0.998192690828598, 0.9992013457914841, 0.9990969696845661, 0.9983573850833438, 0.9965044255015413, 0.9990900086564874, 0.9994947722191293, 0.9982033902299191, 0.99949648341725]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"precision_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9967261726718165, 0.9995283433012266, 0.9995283433012266, 0.9995283433012266, 0.9995283433012266, 0.9995283433012266, 0.9995283433012266, 0.9995283433012266, 0.9995283433012266, 0.9995283433012266, 0.9995283433012266, 0.9995283433012266, 0.9995283433012266, 0.9995283433012266]}], \"weighted_accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"weighted_accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9922699751769376, 0.9999039566473474, 0.9911928555978965, 0.9999331958431323, 0.9999969020952791, 0.9773192821540055, 0.9999284818095976, 0.9998431334518599, 0.9943658550129325, 0.9999969020952791, 0.9998130478947256, 0.9998938729212115, 0.977238976578828, 0.9998688178547167]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"weighted_accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9922699751769376, 0.9999039566473474, 0.9999039566473474, 0.9999331958431323, 0.9999969020952791, 0.9999969020952791, 0.9999969020952791, 0.9999969020952791, 0.9999969020952791, 0.9999969020952791, 0.9999969020952791, 0.9999969020952791, 0.9999969020952791, 0.9999969020952791]}], \"AUC_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"AUC_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.5061277143502855, 0.9714303550280401, 0.97211459565936, 0.9035184183736443, 0.9636612883110603, 0.9780228582516709, 0.9222559353771799, 0.9822722631625892, 0.9723344484019208, 0.964132621530597, 0.9723156897772075, 0.9410135988804355, 0.9743039670944721, 0.9807643284478225]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"AUC_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.5061277143502855, 0.9714303550280401, 0.97211459565936, 0.97211459565936, 0.97211459565936, 0.9780228582516709, 0.9780228582516709, 0.9822722631625892, 0.9822722631625892, 0.9822722631625892, 0.9822722631625892, 0.9822722631625892, 0.9822722631625892, 0.9822722631625892]}], \"matthews_correlation\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"matthews_correlation\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.04877300996086903, 0.862017617374376, 0.37560128708709906, 0.683501958918247, 0.0, 0.23968517343060722, 0.7521268326992147, 0.7298247324872879, 0.4203952759154214, 0.0, 0.7287442444699939, 0.8511086898091516, 0.24080956245183757, 0.8535900055736164]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"matthews_correlation_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.04877300996086903, 0.862017617374376, 0.862017617374376, 0.862017617374376, 0.862017617374376, 0.862017617374376, 0.862017617374376, 0.862017617374376, 0.862017617374376, 0.862017617374376, 0.862017617374376, 0.862017617374376, 0.862017617374376, 0.862017617374376]}], \"average_precision_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"average_precision_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.5023291615058105, 0.9210763668666075, 0.8343437228034581, 0.8534612520439956, 0.8490762285711352, 0.8608807053620167, 0.8759861046913553, 0.8701517344283586, 0.8283047218726383, 0.8348165330907186, 0.855775676129153, 0.9028757119863666, 0.8600080000123042, 0.9228578999343604]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"average_precision_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.5023291615058105, 0.9210763668666075, 0.9210763668666075, 0.9210763668666075, 0.9210763668666075, 0.9210763668666075, 0.9210763668666075, 0.9210763668666075, 0.9210763668666075, 0.9210763668666075, 0.9210763668666075, 0.9210763668666075, 0.9210763668666075, 0.9228578999343604]}], \"f1_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"f1_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.99366115643538, 0.9995250421510861, 0.9942044549015412, 0.9989293611986537, 0.997376776366635, 0.9869307597663179, 0.999156068225545, 0.9990888299416124, 0.9958925956811587, 0.997376776366635, 0.9990861359181141, 0.999487563899046, 0.9868955462080301, 0.9994969752178391]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"f1_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.99366115643538, 0.9995250421510861, 0.9995250421510861, 0.9995250421510861, 0.9995250421510861, 0.9995250421510861, 0.9995250421510861, 0.9995250421510861, 0.9995250421510861, 0.9995250421510861, 0.9995250421510861, 0.9995250421510861, 0.9995250421510861, 0.9995250421510861]}], \"recall_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"recall_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.5558157084874782, 0.8977023276528598, 0.9203329507593235, 0.7516169116897844, 0.5, 0.9408558508081238, 0.8023560462670777, 0.8055782538545581, 0.9218070790969132, 0.5, 0.8118221148468635, 0.8909306627987691, 0.9435628795768801, 0.8991596801842796]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"recall_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.5558157084874782, 0.8977023276528598, 0.9203329507593235, 0.9203329507593235, 0.9203329507593235, 0.9408558508081238, 0.9408558508081238, 0.9408558508081238, 0.9408558508081238, 0.9408558508081238, 0.9408558508081238, 0.9408558508081238, 0.9435628795768801, 0.9435628795768801]}], \"recall_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"markers\", \"name\": \"recall_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9907320804195057, 0.9995438708045347, 0.9909425931680579, 0.9990676922374951, 0.9982506693037042, 0.9771885521916356, 0.9992381140063195, 0.9991629276946349, 0.9941104253826857, 0.9982506693037042, 0.9991529032349669, 0.9995087841404744, 0.9771183791650072, 0.9995137963703083]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"], \"mode\": \"lines\", \"name\": \"recall_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9907320804195057, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347, 0.9995438708045347]}]}, \"metricName\": null, \"primaryMetricName\": \"average_precision_score_weighted\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"AUC_macro\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.9807643284478225]}]}, {\"name\": \"precision_score_weighted\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.99949648341725]}]}, {\"name\": \"recall_score_macro\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.8991596801842796]}]}, {\"name\": \"f1_score_weighted\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.9994969752178391]}]}, {\"name\": \"AUC_micro\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.9999275722047226]}]}, {\"name\": \"average_precision_score_weighted\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.9996831872845306]}]}, {\"name\": \"matthews_correlation\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.8535900055736164]}]}, {\"name\": \"AUC_weighted\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.9807643284478225]}]}, {\"name\": \"weighted_accuracy\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.9998688178547167]}]}, {\"name\": \"precision_score_micro\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.9995137963703083]}]}, {\"name\": \"average_precision_score_micro\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.9999249986598199]}]}, {\"name\": \"norm_macro_recall\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.7983193603685591]}]}, {\"name\": \"accuracy\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.9995137963703083]}]}, {\"name\": \"precision_score_macro\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.956613229815647]}]}, {\"name\": \"f1_score_macro\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.9256996116910283]}]}, {\"name\": \"f1_score_micro\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.9995137963703083]}]}, {\"name\": \"log_loss\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.11458748092259456]}]}, {\"name\": \"recall_score_weighted\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.9995137963703083]}]}, {\"name\": \"average_precision_score_macro\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.9228578999343604]}]}, {\"name\": \"recall_score_micro\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.9995137963703083]}]}, {\"name\": \"balanced_accuracy\", \"run_id\": \"AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00\", \"categories\": [0], \"series\": [{\"data\": [0.8991596801842796]}]}], \"run_logs\": \"\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.38.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(local_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze results\n",
    "\n",
    "#### Retrieve the Best Model\n",
    "\n",
    "Below we select the best pipeline from our iterations. The `get_output` method on `automl_classifier` returns the best run and the fitted model for the last invocation. Overloads on `get_output` allow you to retrieve the best run and fitted model for *any* logged metric or for a particular *iteration*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1646940477107
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineWithYTransformations(Pipeline={'memory': None,\n",
       "                                       'steps': [('datatransformer',\n",
       "                                                  DataTransformer(enable_dnn=False, enable_feature_sweeping=True, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=True, is_onnx_compatible=False, observer=None, task='classification', working_dir='/mn...\n",
       "    gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
       "), random_state=0, reg_alpha=1.875, reg_lambda=0.9375, subsample=0.5, tree_method='auto'))], verbose=False))], flatten_transform=None, weights=[0.4666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.2, 0.06666666666666667]))],\n",
       "                                       'verbose': False},\n",
       "                             y_transformer={},\n",
       "                             y_transformer_name='LabelEncoder')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run, fitted_model = local_run.get_output()\n",
    "fitted_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the properties of the model\n",
    "The fitted_model is a python object and you can read the different properties of the object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "Now that the model is trained, split the data in the same way the data was split for training (The difference here is the data is being split locally) and then run the test data through the trained model to get the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1646952259398
    }
   },
   "outputs": [],
   "source": [
    "# convert the test data to dataframe\n",
    "X_test_df = validation_data.drop_columns(columns=[label_column_name]).to_pandas_dataframe()\n",
    "\n",
    "y_test_df = validation_data.keep_columns(columns=[label_column_name], validate=True).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1646940491212
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the predict functions on the model\n",
    "y_pred = fitted_model.predict(X_test_df)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate metrics for the prediction\n",
    "\n",
    "Now visualize the data on a scatter plot to show what our truth (actual) values are compared to the predicted values \n",
    "from the trained model that was returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1646940491935
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "cf = confusion_matrix(y_test_df.values, y_pred)\n",
    "plt.imshow(cf, cmap=plt.cm.Blues, interpolation=\"nearest\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "class_labels = [\"False\", \"True\"]\n",
    "tick_marks = np.arange(len(class_labels))\n",
    "plt.xticks(tick_marks, class_labels)\n",
    "plt.yticks([-0.5, 0, 1, 1.5], [\"\", \"False\", \"True\", \"\"])\n",
    "# plotting text value inside cells\n",
    "thresh = cf.max() / 2.0\n",
    "for i, j in itertools.product(range(cf.shape[0]), range(cf.shape[1])):\n",
    "    plt.text(\n",
    "        j,\n",
    "        i,\n",
    "        format(cf[i, j], \"d\"),\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"white\" if cf[i, j] > thresh else \"black\",\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "In this section, we will show how to compute model explanations and visualize the explanations using azureml-interpret package. We will also show how to run the automl model and the explainer model through deploying an AKS web service.\n",
    "\n",
    "Besides retrieving an existing model explanation for an AutoML model, you can also explain your AutoML model with different test data. The following steps will allow you to compute and visualize engineered feature importance based on your test data.\n",
    "\n",
    "### Run the explanation\n",
    "#### Download the engineered feature importance from artifact store\n",
    "You can use ExplanationClient to download the engineered feature explanations from the artifact store of the best_run. You can also use azure portal url to view the dash board visualization of the feature importance values of the engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1646940501157
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27:14:43:23,782 INFO     [explanation_client.py:334] Using default datastore for uploads\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'V4_MeanImputer': 0.0673188368222275, 'V14_MeanImputer': 0.03586319006011275, 'V17_MeanImputer': 0.028072865066621454, 'V8_MeanImputer': 0.019549133063068727, 'V12_MeanImputer': 0.016035753323253153, 'V13_MeanImputer': 0.015565214606867776, 'V22_MeanImputer': 0.0149421116316385, 'V11_MeanImputer': 0.013829874644517098, 'Time_MeanImputer': 0.012446055694371056, 'V7_MeanImputer': 0.010750257862506307, 'V18_MeanImputer': 0.008978232502008474, 'V10_MeanImputer': 0.007299233239741598, 'V5_MeanImputer': 0.0063120310124227695, 'Amount_MeanImputer': 0.006241303015688428, 'V19_MeanImputer': 0.005942608000477762, 'V26_MeanImputer': 0.005327480991105602, 'V1_MeanImputer': 0.005255373715354525, 'V28_MeanImputer': 0.004953200955075525, 'V2_MeanImputer': 0.004124763897936349, 'V16_MeanImputer': 0.004029335263499985, 'V25_MeanImputer': 0.0038285371847652833, 'V24_MeanImputer': 0.0025587610210930853, 'V21_MeanImputer': 0.0023784854241159026, 'V15_MeanImputer': 0.001654782603682882, 'V6_MeanImputer': 0.0016333833299713926, 'V3_MeanImputer': 0.001601331518337637, 'V9_MeanImputer': 0.0009529664639982349, 'V23_MeanImputer': 0.0009017160052017162, 'V27_MeanImputer': 0.0005506715846266405, 'V20_MeanImputer': 0.0004379849489903072}\n",
      "You can visualize the engineered explanations under the 'Explanations (preview)' tab in the AutoML run at:-\n",
      "https://ml.azure.com/runs/AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_13?wsid=/subscriptions/d83b98a9-eaa6-475f-9ae6-1ef35394a1e5/resourcegroups/rg-ml-workspace/workspaces/shepml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "client = ExplanationClient.from_run(best_run)\n",
    "engineered_explanations = client.download_model_explanation(raw=False)\n",
    "print(engineered_explanations.get_feature_importance_dict())\n",
    "print(\n",
    "    \"You can visualize the engineered explanations under the 'Explanations (preview)' tab in the AutoML run at:-\\n\"\n",
    "    + best_run.get_portal_url()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the raw feature importance from artifact store\n",
    "You can use ExplanationClient to download the raw feature explanations from the artifact store of the best_run. You can also use azure portal url to view the dash board visualization of the feature importance values of the raw features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gather": {
     "logged": 1646940512993
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'V4': 0.0673188368222275, 'V14': 0.03586319006011275, 'V17': 0.028072865066621454, 'V8': 0.019549133063068727, 'V12': 0.016035753323253153, 'V13': 0.015565214606867776, 'V22': 0.0149421116316385, 'V11': 0.013829874644517098, 'Time': 0.012446055694371056, 'V7': 0.010750257862506307, 'V18': 0.008978232502008474, 'V10': 0.007299233239741598, 'V5': 0.0063120310124227695, 'Amount': 0.006241303015688428, 'V19': 0.005942608000477762, 'V26': 0.005327480991105602, 'V1': 0.005255373715354525, 'V28': 0.004953200955075525, 'V2': 0.004124763897936349, 'V16': 0.004029335263499985, 'V25': 0.0038285371847652833, 'V24': 0.0025587610210930853, 'V21': 0.0023784854241159026, 'V15': 0.001654782603682882, 'V6': 0.0016333833299713926, 'V3': 0.001601331518337637, 'V9': 0.0009529664639982349, 'V23': 0.0009017160052017162, 'V27': 0.0005506715846266405, 'V20': 0.0004379849489903072}\n",
      "You can visualize the raw explanations under the 'Explanations (preview)' tab in the AutoML run at:-\n",
      "https://ml.azure.com/runs/AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_13?wsid=/subscriptions/d83b98a9-eaa6-475f-9ae6-1ef35394a1e5/resourcegroups/rg-ml-workspace/workspaces/shepml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "raw_explanations = client.download_model_explanation(raw=True)\n",
    "print(raw_explanations.get_feature_importance_dict())\n",
    "print(\n",
    "    \"You can visualize the raw explanations under the 'Explanations (preview)' tab in the AutoML run at:-\\n\"\n",
    "    + best_run.get_portal_url()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve any other AutoML model from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1646940828010
    }
   },
   "outputs": [],
   "source": [
    "automl_run, fitted_model = local_run.get_output(metric=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the model explanations for AutoML models\n",
    "The fitted_model can generate the following which will be used for getting the engineered explanations using automl_setup_model_explanations:-\n",
    "\n",
    "1. Featurized data from train samples/test samples\n",
    "2. Gather engineered name lists\n",
    "3. Find the classes in your labeled column in classification scenarios\n",
    "\n",
    "The automl_explainer_setup_obj contains all the structures from above list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1646941021112
    }
   },
   "outputs": [],
   "source": [
    "X_train = training_data.drop_columns(columns=[label_column_name])\n",
    "y_train = training_data.keep_columns(columns=[label_column_name], validate=True)\n",
    "X_test = validation_data.drop_columns(columns=[label_column_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1646941033747
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: Setting up data for AutoML explanations\n",
      "Current status: Setting up the AutoML featurizer\n",
      "Current status: Setting up the AutoML estimator\n",
      "Current status: Setting up the AutoML featurization for explanations\n",
      "Current status: Downsampling of evaluation samples from 85302 to 5000 samples\n",
      "Current status: Generating a feature map for raw feature importance\n",
      "Current status: Finding all classes from the dataset\n",
      "Current status: Choosing the surrogate model as LightGBM for the AutoML model\n",
      "Current status: Data for AutoML explanations successfully setup\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.automl.runtime.automl_explain_utilities import (\n",
    "    automl_setup_model_explanations,\n",
    ")\n",
    "\n",
    "automl_explainer_setup_obj = automl_setup_model_explanations(\n",
    "    fitted_model,\n",
    "    X=X_train,\n",
    "    X_test=X_test,\n",
    "    y=y_train,\n",
    "    task=\"classification\",\n",
    "    automl_run=automl_run,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Mimic Explainer for feature importance\n",
    "For explaining the AutoML models, use the MimicWrapper from azureml-interpret package. The MimicWrapper can be initialized with fields in automl_explainer_setup_obj, your workspace and a surrogate model to explain the AutoML model (fitted_model here). The MimicWrapper also takes the automl_run object where engineered explanations will be uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gather": {
     "logged": 1646941290885
    }
   },
   "outputs": [],
   "source": [
    "from azureml.interpret.mimic_wrapper import MimicWrapper\n",
    "\n",
    "explainer = MimicWrapper(\n",
    "    ws,\n",
    "    automl_explainer_setup_obj.automl_estimator,\n",
    "    explainable_model=automl_explainer_setup_obj.surrogate_model,\n",
    "    init_dataset=automl_explainer_setup_obj.X_transform,\n",
    "    run=automl_explainer_setup_obj.automl_run,\n",
    "    features=automl_explainer_setup_obj.engineered_feature_names,\n",
    "    feature_maps=[automl_explainer_setup_obj.feature_map],\n",
    "    classes=automl_explainer_setup_obj.classes,\n",
    "    explainer_kwargs=automl_explainer_setup_obj.surrogate_model_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Mimic Explainer for computing and visualizing engineered feature importance\n",
    "The explain() method in MimicWrapper can be called with the transformed test samples to get the feature importance for the generated engineered features. You can also use azure portal url to view the dash board visualization of the feature importance values of the engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gather": {
     "logged": 1646941304747
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27:14:44:32,587 INFO     [explanation_client.py:334] Using default datastore for uploads\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'V14_MeanImputer': 0.024853115043223403, 'V10_MeanImputer': 0.006494493464911045, 'V12_MeanImputer': 0.005668941712183879, 'V17_MeanImputer': 0.005122254205512521, 'V4_MeanImputer': 0.003802679161834286, 'V7_MeanImputer': 0.003239871900682652, 'V16_MeanImputer': 0.0014242052277191784, 'V20_MeanImputer': 0.0008590682149309016, 'Amount_MeanImputer': 0.0007699505718363755, 'V26_MeanImputer': 0.0007316543134070712, 'Time_MeanImputer': 0.0006264082881110775, 'V8_MeanImputer': 0.0005501875810798955, 'V13_MeanImputer': 0.00045018942302538055, 'V11_MeanImputer': 0.00042923689400541976, 'V21_MeanImputer': 0.0004174083998013237, 'V28_MeanImputer': 0.0003556475172168774, 'V19_MeanImputer': 0.00033918788668857404, 'V1_MeanImputer': 0.00033372881188365215, 'V6_MeanImputer': 0.00032331442269940684, 'V22_MeanImputer': 0.0002769350006335809, 'V18_MeanImputer': 0.0002721160929392501, 'V15_MeanImputer': 0.00025339765286436466, 'V5_MeanImputer': 0.00025161493676007147, 'V27_MeanImputer': 0.0002226060069872022, 'V25_MeanImputer': 0.00019788751446829918, 'V9_MeanImputer': 0.0001925444702365733, 'V3_MeanImputer': 0.00017216540022846945, 'V23_MeanImputer': 0.00015375466227811378, 'V24_MeanImputer': 0.00012773281740144512, 'V2_MeanImputer': 0.00011504062139227788}\n",
      "You can visualize the engineered explanations under the 'Explanations (preview)' tab in the AutoML run at:-\n",
      "https://ml.azure.com/runs/AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_1?wsid=/subscriptions/d83b98a9-eaa6-475f-9ae6-1ef35394a1e5/resourcegroups/rg-ml-workspace/workspaces/shepml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "# Compute the engineered explanations\n",
    "engineered_explanations = explainer.explain(\n",
    "    [\"local\", \"global\"], eval_dataset=automl_explainer_setup_obj.X_test_transform\n",
    ")\n",
    "print(engineered_explanations.get_feature_importance_dict())\n",
    "print(\n",
    "    \"You can visualize the engineered explanations under the 'Explanations (preview)' tab in the AutoML run at:-\\n\"\n",
    "    + automl_run.get_portal_url()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Mimic Explainer for computing and visualizing raw feature importance\n",
    "The explain() method in MimicWrapper can be called with the transformed test samples to get the feature importance for the original features in your data. You can also use azure portal url to view the dash board visualization of the feature importance values of the original/raw features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gather": {
     "logged": 1646942194467
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27:14:44:40,507 INFO     [explanation_client.py:334] Using default datastore for uploads\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'V14': 0.024853115043223403, 'V10': 0.006494493464911045, 'V12': 0.005668941712183879, 'V17': 0.005122254205512521, 'V4': 0.003802679161834286, 'V7': 0.003239871900682652, 'V16': 0.0014242052277191784, 'V20': 0.0008590682149309016, 'Amount': 0.0007699505718363755, 'V26': 0.0007316543134070712, 'Time': 0.0006264082881110775, 'V8': 0.0005501875810798955, 'V13': 0.00045018942302538055, 'V11': 0.00042923689400541976, 'V21': 0.0004174083998013237, 'V28': 0.0003556475172168774, 'V19': 0.00033918788668857404, 'V1': 0.00033372881188365215, 'V6': 0.00032331442269940684, 'V22': 0.0002769350006335809, 'V18': 0.0002721160929392501, 'V15': 0.00025339765286436466, 'V5': 0.00025161493676007147, 'V27': 0.0002226060069872022, 'V25': 0.00019788751446829918, 'V9': 0.0001925444702365733, 'V3': 0.00017216540022846945, 'V23': 0.00015375466227811378, 'V24': 0.00012773281740144512, 'V2': 0.00011504062139227788}\n",
      "You can visualize the raw explanations under the 'Explanations (preview)' tab in the AutoML run at:-\n",
      "https://ml.azure.com/runs/AutoML_a3ac3461-6038-4e17-a5a6-f06de5ef6f00_1?wsid=/subscriptions/d83b98a9-eaa6-475f-9ae6-1ef35394a1e5/resourcegroups/rg-ml-workspace/workspaces/shepml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "# Compute the raw explanations\n",
    "raw_explanations = explainer.explain(\n",
    "    [\"local\", \"global\"],\n",
    "    get_raw=True,\n",
    "    raw_feature_names=automl_explainer_setup_obj.raw_feature_names,\n",
    "    eval_dataset=automl_explainer_setup_obj.X_test_transform,\n",
    "    raw_eval_dataset=automl_explainer_setup_obj.X_test_raw,\n",
    ")\n",
    "print(raw_explanations.get_feature_importance_dict())\n",
    "print(\n",
    "    \"You can visualize the raw explanations under the 'Explanations (preview)' tab in the AutoML run at:-\\n\"\n",
    "    + automl_run.get_portal_url()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the scoring Explainer, save and upload it for later use in scoring explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "gather": {
     "logged": 1646942216770
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml._restclient.models.batch_artifact_content_information_dto.BatchArtifactContentInformationDto at 0x7f41b1bacc50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.interpret.scoring.scoring_explainer import TreeScoringExplainer\n",
    "import joblib\n",
    "\n",
    "# Initialize the ScoringExplainer\n",
    "scoring_explainer = TreeScoringExplainer(\n",
    "    explainer.explainer, feature_maps=[automl_explainer_setup_obj.feature_map]\n",
    ")\n",
    "\n",
    "# Pickle scoring explainer locally to './scoring_explainer.pkl'\n",
    "scoring_explainer_file_name = \"scoring_explainer.pkl\"\n",
    "with open(scoring_explainer_file_name, \"wb\") as stream:\n",
    "    joblib.dump(scoring_explainer, stream)\n",
    "\n",
    "# Upload the scoring explainer to the automl run\n",
    "automl_run.upload_file(\"outputs/scoring_explainer.pkl\", scoring_explainer_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying the scoring and explainer models to a web service to Azure Kubernetes Service (AKS)\n",
    "\n",
    "We use the TreeScoringExplainer from azureml.interpret package to create the scoring explainer which will be used to compute the raw and engineered feature importances at the inference time. In the cell below, we register the AutoML model and the scoring explainer with the Model Management Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "gather": {
     "logged": 1646942233194
    }
   },
   "outputs": [],
   "source": [
    "# Register trained automl model present in the 'outputs' folder in the artifacts\n",
    "original_model = automl_run.register_model(\n",
    "    model_name=\"automl_model\", model_path=\"outputs/model.pkl\"\n",
    ")\n",
    "scoring_explainer_model = automl_run.register_model(\n",
    "    model_name=\"scoring_explainer\", model_path=\"outputs/scoring_explainer.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the conda dependencies for setting up the service\n",
    "\n",
    "We need to download the conda dependencies using the automl_run object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gather": {
     "logged": 1646942236938
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220113.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": \"2g\"\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"myenv\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-train-automl-runtime==1.38.0\",\n",
       "                        \"inference-schema\",\n",
       "                        \"azureml-interpret==1.38.0\",\n",
       "                        \"azureml-defaults==1.38.0\"\n",
       "                    ]\n",
       "                },\n",
       "                \"numpy>=1.16.0,<1.19.0\",\n",
       "                \"pandas==0.25.1\",\n",
       "                \"scikit-learn==0.22.1\",\n",
       "                \"py-xgboost<=0.90\",\n",
       "                \"fbprophet==0.5\",\n",
       "                \"holidays==0.9.11\",\n",
       "                \"psutil>=5.2.2,<6.0.0\"\n",
       "            ],\n",
       "            \"name\": \"project_environment\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": null\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.automl.core.shared import constants\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "automl_run.download_file(constants.CONDA_ENV_FILE_PATH, \"myenv.yml\")\n",
    "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=\"myenv.yml\")\n",
    "myenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write the Entry Script\n",
    "Write the script that will be used to predict on your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from azureml.core.model import Model\n",
    "from azureml.train.automl.runtime.automl_explain_utilities import (\n",
    "    automl_setup_model_explanations,\n",
    ")\n",
    "\n",
    "\n",
    "def init():\n",
    "    global automl_model\n",
    "    global scoring_explainer\n",
    "\n",
    "    # Retrieve the path to the model file using the model name\n",
    "    # Assume original model is named original_prediction_model\n",
    "    automl_model_path = Model.get_model_path(\"automl_model\")\n",
    "    scoring_explainer_path = Model.get_model_path(\"scoring_explainer\")\n",
    "\n",
    "    automl_model = joblib.load(automl_model_path)\n",
    "    scoring_explainer = joblib.load(scoring_explainer_path)\n",
    "\n",
    "\n",
    "def run(raw_data):\n",
    "    data = pd.read_json(raw_data, orient=\"records\")\n",
    "    # Make prediction\n",
    "    predictions = automl_model.predict(data)\n",
    "    # Setup for inferencing explanations\n",
    "    automl_explainer_setup_obj = automl_setup_model_explanations(\n",
    "        automl_model, X_test=data, task=\"classification\"\n",
    "    )\n",
    "    # Retrieve model explanations for engineered explanations\n",
    "    engineered_local_importance_values = scoring_explainer.explain(\n",
    "        automl_explainer_setup_obj.X_test_transform\n",
    "    )\n",
    "    # Retrieve model explanations for raw explanations\n",
    "    raw_local_importance_values = scoring_explainer.explain(\n",
    "        automl_explainer_setup_obj.X_test_transform, get_raw=True\n",
    "    )\n",
    "    # You can return any data type as long as it is JSON-serializable\n",
    "    return {\n",
    "        \"predictions\": predictions.tolist(),\n",
    "        \"engineered_local_importance_values\": engineered_local_importance_values,\n",
    "        \"raw_local_importance_values\": raw_local_importance_values,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the InferenceConfig \n",
    "Create the inference config that will be used when deploying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "gather": {
     "logged": 1646942252103
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inf_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provision the AKS Cluster\n",
    "This is a one time setup. You can reuse this cluster for multiple deployments after it has been created. If you delete the cluster or the resource group that contains it, then you would have to recreate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "gather": {
     "logged": 1646942739214
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress............................................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "aks_name = \"scoring-explain\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    aks_target = ComputeTarget(workspace=ws, name=aks_name)\n",
    "    print(\"Found existing cluster, use it.\")\n",
    "except ComputeTargetException:\n",
    "    prov_config = AksCompute.provisioning_configuration(vm_size=\"STANDARD_D3_V2\")\n",
    "    aks_target = ComputeTarget.create(\n",
    "        workspace=ws, name=aks_name, provisioning_configuration=prov_config\n",
    "    )\n",
    "aks_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy web service to AKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "gather": {
     "logged": 1646942739420
    }
   },
   "outputs": [],
   "source": [
    "# Set the web service configuration (using default here)\n",
    "from azureml.core.webservice import AksWebservice\n",
    "from azureml.core.model import Model\n",
    "\n",
    "aks_config = AksWebservice.deploy_configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gather": {
     "logged": 1646943694499
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-10-27 14:51:19+00:00 Creating Container Registry if not exists.\n",
      "2022-10-27 14:51:19+00:00 Registering the environment.\n",
      "2022-10-27 14:51:21+00:00 Use the existing image..\n",
      "2022-10-27 14:51:25+00:00 Creating resources in AKS.\n",
      "2022-10-27 14:51:26+00:00 Submitting deployment to compute.\n",
      "2022-10-27 14:51:26+00:00 Checking the status of deployment model-scoring-local-aks..\n",
      "2022-10-27 15:01:10+00:00 Checking the status of inference endpoint model-scoring-local-aks.\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "aks_service_name = \"model-scoring-local-aks\"\n",
    "\n",
    "aks_service = Model.deploy(\n",
    "    workspace=ws,\n",
    "    name=aks_service_name,\n",
    "    models=[scoring_explainer_model, original_model],\n",
    "    inference_config=inf_config,\n",
    "    deployment_config=aks_config,\n",
    "    deployment_target=aks_target,\n",
    ")\n",
    "\n",
    "aks_service.wait_for_deployment(show_output=True)\n",
    "print(aks_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the service logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-10-27T15:00:57,949997063+00:00 - gunicorn/run \\nDynamic Python package installation is disabled.\\nStarting HTTP server\\n2022-10-27T15:00:57,952337572+00:00 - nginx/run \\n2022-10-27T15:00:57,951617969+00:00 - iot-server/run \\n2022-10-27T15:00:57,963967620+00:00 - rsyslog/run \\nrsyslogd: /azureml-envs/azureml_4943656157e05766fedf432d8be562a4/lib/libuuid.so.1: no version information available (required by rsyslogd)\\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2022-10-27T15:00:58,026243678+00:00 - iot-server/finish 1 0\\n2022-10-27T15:00:58,027512883+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 20.1.0\\nListening at: http://127.0.0.1:31311 (11)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 41\\nSPARK_HOME not set. Skipping PySpark Initialization.\\nGenerating new fontManager, this may take some time...\\nFailure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (urllib3 1.26.8 (/azureml-envs/azureml_4943656157e05766fedf432d8be562a4/lib/python3.6/site-packages), Requirement.parse(\\'urllib3<=1.26.7,>=1.23\\'), {\\'azureml-core\\'}).\\nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (urllib3 1.26.8 (/azureml-envs/azureml_4943656157e05766fedf432d8be562a4/lib/python3.6/site-packages), Requirement.parse(\\'urllib3<=1.26.7,>=1.23\\'), {\\'azureml-core\\'}).\\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (urllib3 1.26.8 (/azureml-envs/azureml_4943656157e05766fedf432d8be562a4/lib/python3.6/site-packages), Requirement.parse(\\'urllib3<=1.26.7,>=1.23\\')).\\nInitializing logger\\n2022-10-27 15:01:02,505 | root | INFO | Starting up app insights client\\nlogging socket was found. logging is available.\\nlogging socket was found. logging is available.\\n2022-10-27 15:01:02,505 | root | INFO | Starting up request id generator\\n2022-10-27 15:01:02,505 | root | INFO | Starting up app insight hooks\\n2022-10-27 15:01:02,505 | root | INFO | Invoking user\\'s init function\\n2022-10-27 15:01:03,129 | root | INFO | Users\\'s init has completed successfully\\n2022-10-27 15:01:03,132 | root | INFO | Skipping middleware: dbg_model_info as it\\'s not enabled.\\n2022-10-27 15:01:03,132 | root | INFO | Skipping middleware: dbg_resource_usage as it\\'s not enabled.\\n2022-10-27 15:01:03,133 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\\n2022-10-27 15:01:10,239 | root | INFO | Swagger file not present\\n2022-10-27 15:01:10,239 | root | INFO | 404\\n127.0.0.1 - - [27/Oct/2022:15:01:10 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"hackney/1.18.1\"\\n2022-10-27 15:01:10,398 | root | INFO | Swagger file not present\\n2022-10-27 15:01:10,399 | root | INFO | 404\\n127.0.0.1 - - [27/Oct/2022:15:01:10 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.80.0\"\\n2022-10-27 15:01:11,449 | root | INFO | Swagger file not present\\n2022-10-27 15:01:11,449 | root | INFO | 404\\n127.0.0.1 - - [27/Oct/2022:15:01:11 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"hackney/1.18.1\"\\n2022-10-27 15:01:12,176 | root | INFO | Swagger file not present\\n2022-10-27 15:01:12,176 | root | INFO | 404\\n127.0.0.1 - - [27/Oct/2022:15:01:12 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.80.0\"\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aks_service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consume the web service using run method to do the scoring and explanation of scoring.\n",
    "#### We test the web sevice by passing data. Run() method retrieves API keys behind the scenes to make sure that call is authenticated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Create fake larger dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "gather": {
     "logged": 1646951726836
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use more than one record \n",
    "#use a larger data set by passing in training data just for fun \n",
    "#X_test_df = training_data.drop_columns(columns=[label_column_name]).to_pandas_dataframe()\n",
    "\n",
    "# Serialize the first row of the test data into json\n",
    "#X_test_json = X_test_df.to_json(orient=\"records\")\n",
    "X_test_json = X_test_df.to_json(orient=\"records\")\n",
    "#print(X_test_json)\n",
    "\n",
    "# Call the service to get the predictions and the engineered and raw explanations\n",
    "output = aks_service.run(X_test_json)\n",
    "\n",
    "# Print the predicted value\n",
    "print(\"predictions:\\n{}\\n\".format(output[\"predictions\"]))\n",
    "# Print the engineered feature importances for the predicted value\n",
    "print(\n",
    "    \"engineered_local_importance_values:\\n{}\\n\".format(\n",
    "        output[\"engineered_local_importance_values\"]\n",
    "    )\n",
    ")\n",
    "# Print the raw feature importances for the predicted value\n",
    "print(\n",
    "    \"raw_local_importance_values:\\n{}\\n\".format(output[\"raw_local_importance_values\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-10-27T15:00:57,949997063+00:00 - gunicorn/run \\nDynamic Python package installation is disabled.\\nStarting HTTP server\\n2022-10-27T15:00:57,952337572+00:00 - nginx/run \\n2022-10-27T15:00:57,951617969+00:00 - iot-server/run \\n2022-10-27T15:00:57,963967620+00:00 - rsyslog/run \\nrsyslogd: /azureml-envs/azureml_4943656157e05766fedf432d8be562a4/lib/libuuid.so.1: no version information available (required by rsyslogd)\\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2022-10-27T15:00:58,026243678+00:00 - iot-server/finish 1 0\\n2022-10-27T15:00:58,027512883+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 20.1.0\\nListening at: http://127.0.0.1:31311 (11)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 41\\nSPARK_HOME not set. Skipping PySpark Initialization.\\nGenerating new fontManager, this may take some time...\\nFailure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (urllib3 1.26.8 (/azureml-envs/azureml_4943656157e05766fedf432d8be562a4/lib/python3.6/site-packages), Requirement.parse(\\'urllib3<=1.26.7,>=1.23\\'), {\\'azureml-core\\'}).\\nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (urllib3 1.26.8 (/azureml-envs/azureml_4943656157e05766fedf432d8be562a4/lib/python3.6/site-packages), Requirement.parse(\\'urllib3<=1.26.7,>=1.23\\'), {\\'azureml-core\\'}).\\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (urllib3 1.26.8 (/azureml-envs/azureml_4943656157e05766fedf432d8be562a4/lib/python3.6/site-packages), Requirement.parse(\\'urllib3<=1.26.7,>=1.23\\')).\\nInitializing logger\\n2022-10-27 15:01:02,505 | root | INFO | Starting up app insights client\\nlogging socket was found. logging is available.\\nlogging socket was found. logging is available.\\n2022-10-27 15:01:02,505 | root | INFO | Starting up request id generator\\n2022-10-27 15:01:02,505 | root | INFO | Starting up app insight hooks\\n2022-10-27 15:01:02,505 | root | INFO | Invoking user\\'s init function\\n2022-10-27 15:01:03,129 | root | INFO | Users\\'s init has completed successfully\\n2022-10-27 15:01:03,132 | root | INFO | Skipping middleware: dbg_model_info as it\\'s not enabled.\\n2022-10-27 15:01:03,132 | root | INFO | Skipping middleware: dbg_resource_usage as it\\'s not enabled.\\n2022-10-27 15:01:03,133 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\\n2022-10-27 15:01:10,239 | root | INFO | Swagger file not present\\n2022-10-27 15:01:10,239 | root | INFO | 404\\n127.0.0.1 - - [27/Oct/2022:15:01:10 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"hackney/1.18.1\"\\n2022-10-27 15:01:10,398 | root | INFO | Swagger file not present\\n2022-10-27 15:01:10,399 | root | INFO | 404\\n127.0.0.1 - - [27/Oct/2022:15:01:10 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.80.0\"\\n2022-10-27 15:01:11,449 | root | INFO | Swagger file not present\\n2022-10-27 15:01:11,449 | root | INFO | 404\\n127.0.0.1 - - [27/Oct/2022:15:01:11 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"hackney/1.18.1\"\\n2022-10-27 15:01:12,176 | root | INFO | Swagger file not present\\n2022-10-27 15:01:12,176 | root | INFO | 404\\n127.0.0.1 - - [27/Oct/2022:15:01:12 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.80.0\"\\n2022-10-27 15:01:16,232 | root | INFO | Scoring Timer is set to 3600.0 seconds\\nCurrent status: Setting up data for AutoML explanations\\n2712cfd7-8776-4225-9f8f-4c39793819b6,Current status: Setting up data for AutoML explanations\\n\\nCurrent status: Setting up the AutoML featurizer\\n2712cfd7-8776-4225-9f8f-4c39793819b6,Current status: Setting up the AutoML featurizer\\n\\nCurrent status: Setting up the AutoML estimator\\n2712cfd7-8776-4225-9f8f-4c39793819b6,Current status: Setting up the AutoML estimator\\n\\nCurrent status: Setting up the AutoML featurization for explanations\\n2712cfd7-8776-4225-9f8f-4c39793819b6,Current status: Setting up the AutoML featurization for explanations\\n\\nCurrent status: Downsampling of evaluation samples from 85302 to 5000 samples\\n2712cfd7-8776-4225-9f8f-4c39793819b6,Current status: Downsampling of evaluation samples from 85302 to 5000 samples\\n\\nCurrent status: Generating a feature map for raw feature importance\\n2712cfd7-8776-4225-9f8f-4c39793819b6,Current status: Generating a feature map for raw feature importance\\n\\nCurrent status: Choosing the surrogate model as LightGBM for the AutoML model\\n2712cfd7-8776-4225-9f8f-4c39793819b6,Current status: Choosing the surrogate model as LightGBM for the AutoML model\\n\\nCurrent status: Data for AutoML explanations successfully setup\\n2712cfd7-8776-4225-9f8f-4c39793819b6,Current status: Data for AutoML explanations successfully setup\\n\\n2022-10-27 15:01:20,682 | root | INFO | 200\\n127.0.0.1 - - [27/Oct/2022:15:01:20 +0000] \"POST /score HTTP/1.0\" 200 7757967 \"-\" \"python-requests/2.27.1\"\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aks_service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "gather": {
     "logged": 1646962977180
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"Time\":0.0,\"V1\":1.191857111,\"V2\":0.266150712,\"V3\":0.166480113,\"V4\":0.448154078,\"V5\":0.060017649,\"V6\":-0.082360809,\"V7\":-0.078802983,\"V8\":0.085101655,\"V9\":-0.255425128,\"V10\":-0.166974414,\"V11\":1.612726661,\"V12\":1.065235311,\"V13\":0.489095016,\"V14\":-0.143772296,\"V15\":0.635558093,\"V16\":0.463917041,\"V17\":-0.114804663,\"V18\":-0.18336127,\"V19\":-0.145783041,\"V20\":-0.069083135,\"V21\":-0.225775248,\"V22\":-0.638671953,\"V23\":0.101288021,\"V24\":-0.339846476,\"V25\":0.167170404,\"V26\":0.125894532,\"V27\":-0.008983099,\"V28\":0.014724169,\"Amount\":2.69}]\n",
      "predictions:\n",
      "[False]\n",
      "\n",
      "engineered_local_importance_values:\n",
      "[[-0.0001751139740772672, -0.00026643150706542017, 7.104241535544661e-05, -0.0028096989219879402, 3.115287569518972e-05, -0.0019238174457909916, -0.00015628852317216865, -0.0084280632140369, -5.564403704491249e-05, -0.0001593193937461804, -0.0005309092079916526, -2.335582271574612e-06, -7.942169478081193e-05, 2.1621217560954775e-05, 0.00026651527356317037, -9.394380190674773e-05, -5.741675736268744e-05, -1.7342478527071258e-05, 6.387701636462473e-05, 7.237638387201932e-06, 1.189303349776857e-05, 6.308921615430415e-05, 8.873137096563397e-05, 0.00010582864992118579, -0.0011360268728963817, -4.315146119870121e-05, 8.92604386475666e-05, -0.0005554524282876118, 0.0002724721886477137, 3.143462082212109e-05]]\n",
      "\n",
      "raw_local_importance_values:\n",
      "[[-0.00026643150706542017, 7.104241535544661e-05, 2.1621217560954775e-05, 0.00010582864992118579, -0.0011360268728963817, -4.315146119870121e-05, 8.92604386475666e-05, -0.0005554524282876118, 0.0002724721886477137, 3.143462082212109e-05, -0.0028096989219879402, 3.115287569518972e-05, -0.0019238174457909916, -0.00015628852317216865, -0.0084280632140369, -5.564403704491249e-05, -0.0001593193937461804, -0.0005309092079916526, -2.335582271574612e-06, -7.942169478081193e-05, 0.00026651527356317037, -9.394380190674773e-05, -5.741675736268744e-05, -1.7342478527071258e-05, 6.387701636462473e-05, 7.237638387201932e-06, 1.189303349776857e-05, 6.308921615430415e-05, 8.873137096563397e-05, -0.0001751139740772672]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Serialize the first row of the test data into json\n",
    "X_test_json = X_test_df[:1].to_json(orient=\"records\")\n",
    "print(X_test_json)\n",
    "\n",
    "# Call the service to get the predictions and the engineered and raw explanations\n",
    "output = aks_service.run(X_test_json)\n",
    "\n",
    "# Print the predicted value\n",
    "print(\"predictions:\\n{}\\n\".format(output[\"predictions\"]))\n",
    "# Print the engineered feature importances for the predicted value\n",
    "print(\n",
    "    \"engineered_local_importance_values:\\n{}\\n\".format(\n",
    "        output[\"engineered_local_importance_values\"]\n",
    "    )\n",
    ")\n",
    "# Print the raw feature importances for the predicted value\n",
    "print(\n",
    "    \"raw_local_importance_values:\\n{}\\n\".format(output[\"raw_local_importance_values\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up\n",
    "Delete the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##aks_service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Credit Card fraud Detection dataset is made available under the Open Database License: http://opendatacommons.org/licenses/odbl/1.0/. Any rights in individual contents of the database are licensed under the Database Contents License: http://opendatacommons.org/licenses/dbcl/1.0/ and is available at: https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "\n",
    "The dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (UniversitÃƒÂ© Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available on https://www.researchgate.net/project/Fraud-detection-5 and the page of the DefeatFraud project\n",
    "Please cite the following works: \n",
    "Ã¢â‚¬Â¢\tAndrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015\n",
    "Ã¢â‚¬Â¢\tDal Pozzolo, Andrea; Caelen, Olivier; Le Borgne, Yann-Ael; Waterschoot, Serge; Bontempi, Gianluca. Learned lessons in credit card fraud detection from a practitioner perspective, Expert systems with applications,41,10,4915-4928,2014, Pergamon\n",
    "Ã¢â‚¬Â¢\tDal Pozzolo, Andrea; Boracchi, Giacomo; Caelen, Olivier; Alippi, Cesare; Bontempi, Gianluca. Credit card fraud detection: a realistic modeling and a novel learning strategy, IEEE transactions on neural networks and learning systems,29,8,3784-3797,2018,IEEE\n",
    "o\tDal Pozzolo, Andrea Adaptive Machine learning for credit card fraud detection ULB MLG PhD thesis (supervised by G. Bontempi)\n",
    "Ã¢â‚¬Â¢\tCarcillo, Fabrizio; Dal Pozzolo, Andrea; Le Borgne, Yann-AÃƒÂ«l; Caelen, Olivier; Mazzer, Yannis; Bontempi, Gianluca. Scarff: a scalable framework for streaming credit card fraud detection with Spark, Information fusion,41, 182-194,2018,Elsevier\n",
    "Ã¢â‚¬Â¢\tCarcillo, Fabrizio; Le Borgne, Yann-AÃƒÂ«l; Caelen, Olivier; Bontempi, Gianluca. Streaming active learning strategies for real-life credit card fraud detection: assessment and visualization, International Journal of Data Science and Analytics, 5,4,285-300,2018,Springer International Publishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "gather": {
     "logged": 1646963139807
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-814bc5db6e1d>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-814bc5db6e1d>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    body = str.encode(json.dumps(data))\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "data = [{\"Time\":0.0,\"V1\":-1.359807134,\"V2\":-0.072781173,\"V3\":2.536346738,\"V4\":1.378155224,\"V5\":-0.33832077,\"V6\":0.462387778,\"V7\":0.239598554,\"V8\":0.098697901,\"V9\":0.36378697,\"V10\":0.090794172,\"V11\":-0.551599533,\"V12\":-0.617800856,\"V13\":-0.991389847,\"V14\":-0.311169354,\"V15\":1.468176972,\"V16\":-0.470400525,\"V17\":0.207971242,\"V18\":0.02579058,\"V19\":0.40399296,\"V20\":0.251412098,\"V21\":-0.018306778,\"V22\":0.277837576,\"V23\":-0.11047391,\"V24\":0.066928075,\"V25\":0.128539358,\"V26\":-0.189114844,\"V27\":0.133558377,\"V28\":-0.021053053,\"Amount\":149.62},\n",
    "\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "url = 'http://52.254.32.196:80/api/v1/service/model-scoring-local-aks/score'\n",
    "api_key = '8fq3WwMvWMYQxjPBFY2MImiHvGcrRchh' # Replace this with the API key for the web service\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(error.read().decode(\"utf8\", 'ignore'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "ratanase"
   }
  ],
  "category": "tutorial",
  "compute": [
   "Local"
  ],
  "datasets": [
   "creditcard"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": true,
  "file_extension": ".py",
  "framework": [
   "None"
  ],
  "friendly_name": "Classification of credit card fraudulent transactions using Automated ML",
  "index_order": 5,
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "pygments_lexer": "ipython3",
  "tags": [
   "local_run",
   "AutomatedML"
  ],
  "task": "Classification",
  "version": "3.6.7"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
